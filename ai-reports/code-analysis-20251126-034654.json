[
  {
    "file": "train.py",
    "timestamp": "2025-11-26T03:45:45.365670",
    "metrics": {
      "complexity": "train.py\n    F 77:0 train_model - A (4)\n    F 47:0 prepare_data - A (3)\n    C 22:0 MedicalDataset - A (2)\n    M 23:4 MedicalDataset.__init__ - A (1)\n    M 28:4 MedicalDataset.__len__ - A (1)\n    M 31:4 MedicalDataset.__getitem__ - A (1)\n",
      "maintainability": "train.py - A (69.54)\n"
    },
    "ai_recommendations": "В целом, код написан хорошо и следует стандартам Python. Однако, есть несколько предложений по улучшению:\n\n1. **Обработка ошибок**: В функции `prepare_data` есть проверка на наличие столбцов 'text' и 'label' в входных данных. Это хорошо, но можно добавить больше проверок на валидность входных данных, например, проверить, что файл существует перед его чтением.\n\n2. **Читаемость**: В функции `__getitem__` класса `MedicalDataset` создается словарь `tokens`, а затем из него извлекаются значения. Это может быть немного запутанно для чтения. Лучше было бы разделить этот код на несколько строк для улучшения читаемости.\n\n3. **Оптимизация производительности**: В функции `train_model` модель обучается в цикле, и на каждой итерации градиенты обнуляются с помощью `optimizer.zero_grad()`. Это необходимо для корректного обновления весов модели, но вызов этой функции может быть дорогостоящим. Чтобы улучшить производительность, можно вызывать `optimizer.zero_grad()` только после того, как градиенты были использованы для обновления весов модели.\n\n4. **Best practices**: В функции `train_model` используется фиксированное число эпох для обучения модели. Это может быть неоптимально, так как модель может переобучиться или недообучиться. Лучше было бы использовать некоторый критерий остановки, например, остановить обучение, когда потери на валидационном наборе данных перестают уменьшаться.\n\n5. **Безопасность**: В коде нет явных проблем с безопасностью. Однако, стоит убедиться, что входные данные не содержат вредоносного кода или неподходящего содержимого, особенно если они получены из ненадежного источника.",
    "lines_of_code": 124
  },
  {
    "file": "main.py",
    "timestamp": "2025-11-26T03:45:59.661896",
    "metrics": {
      "complexity": "main.py\n    F 32:0 train_model - A (4)\n    F 72:0 predict - A (2)\n    C 14:0 MedicalNet - A (2)\n    F 92:0 main - A (1)\n    M 15:4 MedicalNet.__init__ - A (1)\n    M 22:4 MedicalNet.forward - A (1)\n",
      "maintainability": "main.py - A (74.92)\n"
    },
    "ai_recommendations": "В целом, код написан хорошо и читаемо. Однако, есть несколько моментов, которые можно улучшить:\n\n1. **Импорты**: В начале файла импортируется модуль `os`, который не используется в коде. Лучше убрать его, чтобы не засорять пространство имен.\n\n2. **Документация**: Ваш код будет гораздо более понятным и легко поддерживаемым, если вы добавите комментарии и документацию к классам и функциям. Это особенно важно для функций `train_model` и `predict`, где не совсем очевидно, что делают некоторые строки кода.\n\n3. **Обработка ошибок**: Ваш код не обрабатывает ошибки, которые могут возникнуть при работе с файлами (например, при сохранении или загрузке модели). Это может привести к непредсказуемым результатам.\n\n4. **Хардкод**: Ваш код содержит хардкод, например, количество эпох, размер батча и скорость обучения. Лучше вынести эти значения в конфигурационный файл или сделать их параметрами функции.\n\n5. **Производительность**: Ваш код не оптимизирован для работы с большими объемами данных. Например, вы используете цикл для обучения модели, что может быть медленно при работе с большими датасетами. Вместо этого вы можете использовать библиотеку Dataloader, которая оптимизирована для работы с большими объемами данных.\n\n6. **Best practices**: Ваш код не следует некоторым best practices для PyTorch. Например, вы используете функцию `torch.nn.functional.relu` вместо `torch.nn.ReLU`. Последняя является более предпочтительной, так как она поддерживает автоматическое дифференцирование и может быть использована в модулях nn.Sequential.\n\n7. **Тестирование**: Ваш код не содержит тестов, что делает его менее надежным. Лучше добавить тесты для проверки корректности работы функций и методов.",
    "lines_of_code": 111
  },
  {
    "file": "infer.py",
    "timestamp": "2025-11-26T03:46:21.748328",
    "metrics": {
      "complexity": "infer.py\n    F 10:0 infer_model - A (2)\n",
      "maintainability": "infer.py - A (74.30)\n"
    },
    "ai_recommendations": "Ваш код в целом хорошо написан, но есть несколько моментов, которые можно улучшить:\n\n1. **Производительность**: Ваша функция `infer_model` каждый раз загружает модель и токенизатор при вызове. Если вы планируете использовать эту функцию многократно в одной сессии, это может привести к значительным задержкам. Рекомендуется загрузить модель и токенизатор один раз и затем использовать их для всех последующих вызовов.\n\n2. **Читаемость**: Ваш код в целом хорошо структурирован и легко читается. Однако, можно добавить больше комментариев для объяснения, что делает каждая часть кода, особенно для сложных строк, таких как токенизация и получение вероятностей.\n\n3. **Best Practices**: Ваш код следует большинству лучших практик Python и PyTorch. Однако, вы можете добавить обработку исключений для обработки возможных ошибок, таких как отсутствие модели по указанному пути или некорректный ввод текста.\n\nВот пример улучшенного кода:\n\n```python\nimport argparse\nimport torch\nfrom transformers import AutoModelForSequenceClassification, AutoTokenizer\n\n# Настройка устройства\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Загрузка модели и токенизатора\ndef load_model_and_tokenizer(model_dir):\n    tokenizer = AutoTokenizer.from_pretrained(model_dir)\n    model = AutoModelForSequenceClassification.from_pretrained(model_dir)\n    model.to(DEVICE)\n    return tokenizer, model\n\n# Инференс модели\ndef infer_model(tokenizer, model, text):\n    tokens = tokenizer(\n        text, return_tensors=\"pt\", truncation=True, padding=True, max_length=128\n    )\n    tokens = {k: v.to(DEVICE) for k, v in tokens.items()}\n\n    model.eval()\n    with torch.no_grad():\n        outputs = model(**tokens)\n        probabilities = torch.softmax(outputs.logits, dim=-1)\n\n    return probabilities.tolist()\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser(description=\"Инференс с медицинской нейросетью\")\n    parser.add_argument(\"--model\", required=True, help=\"Путь к сохраненной модели\")\n    parser.add_argument(\"--text\", required=True, help=\"Текст для анализа\")\n    args = parser.parse_args()\n\n    try:\n        tokenizer, model = load_model_and_tokenizer(args.model)\n        result = infer_model(tokenizer, model, args.text)\n        print(f\"Результаты предсказания: {result}\")\n    except Exception as e:\n        print(f\"Произошла ошибка: {e}\")\n```\n\n4. **Безопасность**: Ваш код не содержит явных уязвимостей безопасности. Однако, всегда стоит убедиться, что входные данные проверяются на валидность и безопасность, особенно если они получаются из ненадежного источника.",
    "lines_of_code": 35
  },
  {
    "file": "prepare_data.py",
    "timestamp": "2025-11-26T03:46:38.330446",
    "metrics": {
      "complexity": "prepare_data.py\n    F 13:0 prepare_data - A (3)\n",
      "maintainability": "prepare_data.py - A (84.99)\n"
    },
    "ai_recommendations": "В целом, код хорошо написан и следует многим best practices. Он читаем, модульный и легко понимаем. Однако есть несколько областей, где можно внести улучшения:\n\n1. **Обработка исключений**: Ваш код может вызвать исключение, если CSV-файл не содержит нужных столбцов. Это хорошо, но было бы еще лучше, если бы вы добавили более общую обработку исключений для других потенциальных ошибок, таких как проблемы с чтением файла или записью в файл.\n\n2. **Логирование**: Ваш код использует логирование для отслеживания прогресса и диагностики. Это хорошо, но вы можете добавить больше информации в ваши логи, такие как время выполнения каждого шага или подробные сообщения об ошибках.\n\n3. **Оптимизация производительности**: Ваш код может быть неэффективным, если размер данных очень большой. Операции, такие как чтение CSV-файла и разделение данных на обучающую и тестовую выборки, могут занять много времени и памяти. Вы можете улучшить производительность, используя более эффективные методы обработки данных, такие как использование Dask вместо pandas или использование стратифицированного разделения в train_test_split.\n\n4. **Тестирование**: Ваш код не содержит тестов. Хорошей практикой является написание модульных тестов для проверки корректности вашего кода. Вы можете использовать библиотеки, такие как pytest, для написания и запуска тестов.\n\n5. **Документация**: Ваш код содержит комментарии и строки документации, что является хорошей практикой. Однако, вы можете улучшить документацию, добавив больше деталей о том, что делает каждая функция и какие аргументы она принимает. Это поможет другим разработчикам легче понять и использовать ваш код.",
    "lines_of_code": 53
  },
  {
    "file": "scripts/fix_csv_headers.py",
    "timestamp": "2025-11-26T03:46:54.626215",
    "metrics": {
      "complexity": "",
      "maintainability": "scripts/fix_csv_headers.py - A (90.78)\n"
    },
    "ai_recommendations": "В целом, код написан хорошо и читаемо, но есть несколько моментов, которые можно улучшить:\n\n1. **Производительность**: Вместо того, чтобы сначала считывать все строки из файла в список, а затем обрабатывать их, можно считывать и обрабатывать строки по одной. Это снизит потребление памяти, особенно для больших файлов.\n\n2. **Безопасность**: В текущем коде файл сначала открывается для чтения, а затем снова открывается для записи. Если в процессе выполнения программы что-то пойдет не так, исходный файл может быть поврежден. Лучше использовать временный файл для записи обработанных строк, а затем заменить исходный файл этим временным файлом.\n\n3. **Читаемость**: Цикл for можно заменить на генератор списка для более компактного и понятного кода.\n\n4. **Best practices**: Вместо того, чтобы жестко кодировать имя файла в коде, лучше сделать его аргументом командной строки. Это сделает скрипт более универсальным и переиспользуемым.\n\nВот пример улучшенного кода:\n\n```python\n#!/usr/bin/env python3\n\"\"\"Fix CSV file by removing invalid header rows\"\"\"\n\nimport csv\nimport sys\nimport os\nimport argparse\n\ndef parse_args():\n    parser = argparse.ArgumentParser(description='Fix CSV file by removing invalid header rows')\n    parser.add_argument('csv_file', help='Path to the CSV file to fix')\n    return parser.parse_args()\n\ndef main():\n    args = parse_args()\n\n    # Use a temporary file to avoid corrupting the original file\n    with open(args.csv_file, \"r\", encoding=\"utf-8\") as f, \\\n         open(args.csv_file + \".tmp\", \"w\", encoding=\"utf-8\") as f_tmp:\n\n        valid_lines = 0\n        total_lines = 0\n\n        for i, line in enumerate(f):\n            total_lines += 1\n            # Skip if line is just a header without commas\n            if i == 0 or \",\" in line:  # Keep the header row and lines with CSV data\n                f_tmp.write(line)\n                valid_lines += 1\n            else:\n                print(f\"Removing invalid line {i+1}: {line.strip()}\")\n\n    # Replace the original file with the temporary file\n    os.rename(args.csv_file + \".tmp\", args.csv_file)\n\n    print(\n        f\"\\nDone! Kept {valid_lines} valid lines, removed {total_lines - valid_lines} invalid lines\"\n    )\n\nif __name__ == \"__main__\":\n    main()\n```\n\nЭтот код делает то же самое, что и исходный, но он более безопасен, эффективен и универсален.",
    "lines_of_code": 29
  }
]