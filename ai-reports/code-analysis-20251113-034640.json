[
  {
    "file": "train.py",
    "timestamp": "2025-11-13T03:45:06.548256",
    "metrics": {
      "complexity": "train.py\n    F 77:0 train_model - A (4)\n    F 47:0 prepare_data - A (3)\n    C 22:0 MedicalDataset - A (2)\n    M 23:4 MedicalDataset.__init__ - A (1)\n    M 28:4 MedicalDataset.__len__ - A (1)\n    M 31:4 MedicalDataset.__getitem__ - A (1)\n",
      "maintainability": "train.py - A (69.54)\n"
    },
    "ai_recommendations": "В целом, код хорошо структурирован и читаем. Однако, есть несколько мест, которые можно улучшить:\n\n1. **Обработка ошибок**: В функции `prepare_data` вы проверяете наличие столбцов 'text' и 'label' в данных, но если они отсутствуют, вы просто вызываете исключение. Было бы полезно добавить более подробное сообщение об ошибке, указывающее, какие столбцы отсутствуют.\n\n2. **Константы**: Константы, такие как имя модели, размер батча, скорость обучения и т.д., лучше вынести в аргументы командной строки, чтобы можно было легко изменять их без изменения кода.\n\n3. **Очистка данных**: В функции `prepare_data` вы очищаете текст, удаляя пробелы в начале и конце каждой строки. Возможно, вам стоит добавить дополнительную предварительную обработку текста, например, преобразование всех символов в нижний регистр, удаление знаков препинания и т.д.\n\n4. **Оптимизация**: В функции `train_model` вы используете AdamW в качестве оптимизатора. Возможно, стоит рассмотреть использование более продвинутых оптимизаторов, таких как AdamP или Madgrad.\n\n5. **Сохранение промежуточных результатов**: В функции `train_model` вы сохраняете модель только после всех эпох. Возможно, стоит сохранять модель после каждой эпохи или каждых N эпох, чтобы в случае прерывания процесса обучения можно было продолжить с последней сохраненной точки.\n\n6. **Валидация**: Ваш код не включает в себя валидационный процесс. Валидация помогает контролировать процесс обучения и предотвращать переобучение.\n\n7. **Использование GPU**: Вы используете GPU, если он доступен, но не проверяете, есть ли достаточно памяти на GPU. Если на GPU недостаточно памяти для загрузки модели или данных, это вызовет ошибку во время выполнения.",
    "lines_of_code": 124
  },
  {
    "file": "main.py",
    "timestamp": "2025-11-13T03:45:30.769186",
    "metrics": {
      "complexity": "main.py\n    F 32:0 train_model - A (4)\n    F 72:0 predict - A (2)\n    C 14:0 MedicalNet - A (2)\n    F 92:0 main - A (1)\n    M 15:4 MedicalNet.__init__ - A (1)\n    M 22:4 MedicalNet.forward - A (1)\n",
      "maintainability": "main.py - A (74.92)\n"
    },
    "ai_recommendations": "В целом, код написан хорошо, но есть несколько моментов, которые можно улучшить:\n\n1. **Модуль `os` импортирован, но не используется.** Если он не нужен, его следует удалить.\n\n2. **Обработка ошибок.** В текущем коде нет обработки ошибок, что может привести к непредсказуемым результатам. Например, при загрузке модели из файла, если файл не найден, будет выброшено исключение. Хорошей практикой было бы добавить обработку таких ошибок.\n\n3. **Использование GPU.** Ваш код автоматически использует GPU, если он доступен. Это хорошо, но в некоторых случаях пользователь может захотеть использовать CPU, даже если доступен GPU. Рекомендуется добавить аргумент для выбора устройства в функциях `train_model` и `predict`.\n\n4. **Жестко заданные гиперпараметры.** Ваша функция `train_model` имеет жестко заданные гиперпараметры, такие как `epochs` и `batch_size`. Хотя вы предоставляете возможность их изменения при вызове функции, было бы лучше вынести их в аргументы командной строки или конфигурационный файл для большей гибкости.\n\n5. **Логирование.** Вместо прямого использования `print` для вывода информации о процессе обучения, рекомендуется использовать модуль `logging`. Это позволит более гибко управлять выводом информации, а также сохранять логи в файлы.\n\n6. **Комментарии и документация.** Хотя большая часть кода понятна, некоторые части могут быть неясны для людей, не знакомых с PyTorch. Было бы полезно добавить комментарии, объясняющие, что делает каждая часть кода, а также docstrings для функций и классов.\n\n7. **Сохранение и загрузка модели.** Ваш код сохраняет только параметры модели, но не ее структуру. Это означает, что для загрузки модели нужно знать ее точную структуру. Хотя это работает в вашем случае, где структура модели определена в том же файле, что и код для загрузки, это может быть проблемой, если модель нужно загрузить в другом месте. Рекомендуется сохранять всю модель, а не только ее параметры.\n\n8. **Тестирование.** Ваш код не содержит тестов. Хотя это не всегда необходимо, тесты могут помочь обнаружить ошибки и убедиться, что все работает как ожидается.\n\n9. **Хардкод в main().** В функции main() используется хардкод для определения размеров входного и выходного слоя, а также для генерации данных. Это может затруднить повторное использование кода. Лучше передавать эти параметры как аргументы функции или извлекать их из данных.",
    "lines_of_code": 111
  },
  {
    "file": "infer.py",
    "timestamp": "2025-11-13T03:46:06.579470",
    "metrics": {
      "complexity": "infer.py\n    F 10:0 infer_model - A (2)\n",
      "maintainability": "infer.py - A (74.30)\n"
    },
    "ai_recommendations": "В целом, код хорошо написан и следует стандартам Python. Однако есть несколько мест, которые можно улучшить для повышения производительности, читаемости и общих best practices:\n\n1. **Инициализация модели и токенизатора**: В текущем коде, каждый раз при вызове функции `infer_model`, модель и токенизатор загружаются заново. Это может быть неэффективно, если функция вызывается многократно. Рекомендуется загрузить модель и токенизатор один раз и затем использовать их для всех последующих вызовов. \n\n2. **Обработка ошибок**: В коде отсутствует обработка ошибок. Например, что произойдет, если указанный путь к модели некорректен или модель не может быть загружена? Добавление блоков `try/except` может помочь обрабатывать такие ситуации и предотвращать непредвиденные сбои.\n\n3. **Комментарии и документация**: Хотя код в целом читаемый, добавление большего количества комментариев и строк документации может помочь другим разработчикам лучше понять, что делает ваш код.\n\n4. **Тестирование**: В коде отсутствуют тесты. Хорошей практикой является написание модульных тестов для проверки корректности работы функций.\n\n5. **Определение DEVICE**: Определение DEVICE лучше перенести внутрь `if __name__ == \"__main__\":`. Это позволит избежать необходимости определения DEVICE при импорте этого модуля в другой скрипт.\n\n6. **Использование f-string**: В последней строке используется f-string для вывода результатов. Это хорошая практика, но стоит учесть, что f-string доступны только начиная с Python 3.6. Если ваш код должен поддерживать более ранние версии Python, лучше использовать другой способ форматирования строк.\n\n7. **Использование argparse**: argparse - это хороший выбор для обработки аргументов командной строки, но стоит учесть, что есть и другие библиотеки, которые могут предложить более удобный или мощный функционал, например, click или fire.",
    "lines_of_code": 35
  },
  {
    "file": "prepare_data.py",
    "timestamp": "2025-11-13T03:46:25.018282",
    "metrics": {
      "complexity": "prepare_data.py\n    F 13:0 prepare_data - A (3)\n",
      "maintainability": "prepare_data.py - A (84.99)\n"
    },
    "ai_recommendations": "В целом, код хорошо структурирован и легко читаем. Однако есть несколько рекомендаций, которые могут помочь улучшить его:\n\n1. **Обработка исключений**: Ваш код может вызвать исключение, если файл CSV не найден или не может быть прочитан. Хорошей практикой является обработка таких исключений и вывод информативного сообщения об ошибке.\n\n2. **Проверка входных данных**: Хотя вы проверяете наличие необходимых столбцов в данных, возможно, стоит добавить дополнительные проверки входных данных. Например, вы можете проверить, что данные в столбцах 'text' и 'label' не пустые.\n\n3. **Документация**: Ваш код хорошо документирован, но можно добавить больше информации о том, какие данные ожидаются на входе и что будет на выходе. Это поможет другим разработчикам лучше понять ваш код.\n\n4. **Тестирование**: Ваш код не содержит тестов. Хорошей практикой является написание тестов для проверки корректности работы вашего кода. Вы можете использовать библиотеки, такие как pytest, для написания тестов.\n\n5. **Использование констант**: Ваш код использует константу для задания размера тестовой выборки и значения random_state. Это хорошо, но эти значения можно сделать параметрами функции или аргументами командной строки, чтобы увеличить гибкость вашего кода.\n\n6. **Оптимизация производительности**: Ваш код может быть неэффективным, если размер данных очень большой. В этом случае, вы можете рассмотреть возможность использования библиотеки Dask для параллельной обработки данных.",
    "lines_of_code": 53
  },
  {
    "file": "scripts/fix_csv_headers.py",
    "timestamp": "2025-11-13T03:46:40.467682",
    "metrics": {
      "complexity": "",
      "maintainability": "scripts/fix_csv_headers.py - A (90.78)\n"
    },
    "ai_recommendations": "В целом, код написан хорошо и легко читается. Однако есть несколько моментов, которые можно улучшить:\n\n1. **Производительность**: Вместо того, чтобы сначала считывать все строки из файла, а затем итерироваться по ним, можно сразу же итерироваться по файлу. Это позволит сэкономить память, особенно если файл большой.\n\n2. **Безопасность**: В данном случае, код открывает и изменяет файл, не делая резервную копию. Если в процессе записи что-то пойдет не так, исходные данные могут быть потеряны. Лучше всего сохранять измененные данные в новый файл.\n\n3. **Читаемость и best practices**: Вместо использования индекса для проверки первой строки, можно использовать функцию `next()` для чтения заголовка, а затем итерировать по остальным строкам.\n\nВот улучшенная версия кода:\n\n```python\n#!/usr/bin/env python3\n\"\"\"Fix CSV file by removing invalid header rows\"\"\"\n\nimport csv\nimport sys\n\nvalid_lines = []\n\n# Read the CSV file\nwith open(\"training-data/medical_training_data.csv\", \"r\", encoding=\"utf-8\") as f:\n    # Keep the header row\n    valid_lines.append(next(f))\n    \n    # Filter out lines that don't have proper CSV structure\n    # Invalid lines are those that don't contain commas (are just section headers)\n    for i, line in enumerate(f, start=2):  # start=2 because we already read the header\n        if \",\" in line:  # Only keep lines with CSV data\n            valid_lines.append(line)\n        else:\n            print(f\"Removing invalid line {i}: {line.strip()}\")\n\n# Write back the cleaned CSV to a new file\nwith open(\"training-data/medical_training_data_cleaned.csv\", \"w\", encoding=\"utf-8\") as f:\n    f.writelines(valid_lines)\n\nprint(\n    f\"\\nDone! Kept {len(valid_lines)} valid lines, removed {i+1 - len(valid_lines)} invalid lines\"\n)\n```\n\nТакже стоит отметить, что вместо ручной обработки CSV-файлов, можно использовать библиотеки, такие как pandas, которые предоставляют более мощные и гибкие инструменты для работы с данными.",
    "lines_of_code": 29
  }
]