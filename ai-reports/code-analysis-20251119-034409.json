[
  {
    "file": "train.py",
    "timestamp": "2025-11-19T03:42:48.541763",
    "metrics": {
      "complexity": "train.py\n    F 77:0 train_model - A (4)\n    F 47:0 prepare_data - A (3)\n    C 22:0 MedicalDataset - A (2)\n    M 23:4 MedicalDataset.__init__ - A (1)\n    M 28:4 MedicalDataset.__len__ - A (1)\n    M 31:4 MedicalDataset.__getitem__ - A (1)\n",
      "maintainability": "train.py - A (69.54)\n"
    },
    "ai_recommendations": "Ваш код в целом хорошо структурирован и читаем, но есть несколько моментов, которые можно улучшить:\n\n1. **Обработка ошибок**: Ваш код не обрабатывает ошибки, которые могут возникнуть при чтении файла CSV или при обучении модели. Вместо того чтобы просто вызывать исключение, вы можете добавить блоки try/except, чтобы обработать эти ошибки и предоставить более понятные сообщения об ошибках.\n\n2. **Константы**: Вы используете константы, такие как MODEL_NAME и DEVICE, в разных частях кода. Это хорошая практика, но вы можете сделать ее еще лучше, вынеся все константы в отдельный файл или в начало вашего скрипта.\n\n3. **Комментарии и документация**: Ваш код содержит некоторые комментарии, но они не всегда полезны. Например, комментарий \"# Заготовка для датасета\" не дает много информации. Старайтесь делать комментарии более информативными и полезными. Также добавьте строки документации (docstrings) к вашим функциям и классам для более подробного описания их назначения и поведения.\n\n4. **Оптимизация**: Ваш код может быть оптимизирован для улучшения производительности. Например, вы можете использовать более эффективные алгоритмы или структуры данных, или вы можете использовать библиотеки, которые оптимизированы для быстрого выполнения операций, которые вы выполняете.\n\n5. **Тестирование**: Ваш код не содержит тестов. Хорошая практика - написание тестов для проверки корректности работы вашего кода. Вы можете использовать библиотеки, такие как pytest, для написания тестов.\n\n6. **Разделение кода**: Ваш код содержит все в одном файле. Хорошей практикой является разделение кода на несколько файлов или модулей по функциональности. Это улучшает читаемость и поддерживаемость кода.\n\n7. **Использование GPU**: Ваш код использует GPU, если он доступен. Это хорошо, но вы должны убедиться, что ваш код эффективно использует GPU. Например, вы можете использовать библиотеки, такие как CuPy или Numba, для ускорения вычислений на GPU.\n\n8. **Параметры обучения**: Параметры обучения, такие как количество эпох, размер пакета и скорость обучения, задаются в коде. Хорошей практикой является передача этих параметров как аргументов командной строки, чтобы вы могли легко изменять их без изменения кода.",
    "lines_of_code": 124
  },
  {
    "file": "main.py",
    "timestamp": "2025-11-19T03:43:04.746046",
    "metrics": {
      "complexity": "main.py\n    F 32:0 train_model - A (4)\n    F 72:0 predict - A (2)\n    C 14:0 MedicalNet - A (2)\n    F 92:0 main - A (1)\n    M 15:4 MedicalNet.__init__ - A (1)\n    M 22:4 MedicalNet.forward - A (1)\n",
      "maintainability": "main.py - A (74.92)\n"
    },
    "ai_recommendations": "В целом, код хорошо структурирован и читаем, но есть несколько моментов, которые можно улучшить:\n\n1. **Использование GPU**: Вы используете GPU, если он доступен. Это хорошо, но вы должны убедиться, что ваши данные и модель находятся на одном и том же устройстве (CPU или GPU). В противном случае, вы можете столкнуться с ошибками. В вашем коде вы уже делаете это, но стоит об этом помнить.\n\n2. **Обработка ошибок**: Ваш код не обрабатывает ошибки. Например, что произойдет, если файл модели не найден при попытке загрузить его? Лучше всего добавить блоки try/except для обработки таких ситуаций.\n\n3. **Кодирование классов**: Ваш код предполагает, что метки уже закодированы в виде целых чисел. Если это не так, вы можете столкнуться с ошибками. Лучше всего добавить код для кодирования меток в нужный формат.\n\n4. **Сохранение и загрузка модели**: Вы сохраняете только параметры модели, а не всю модель. Это может быть проблемой, если архитектура модели изменится в будущем. Лучше всего сохранять всю модель, включая ее архитектуру.\n\n5. **Использование Dropout во время инференции**: Dropout должен использоваться только во время обучения, а не во время инференции. В вашем коде вы используете Dropout в методе forward, который используется как во время обучения, так и во время инференции. Лучше всего использовать Dropout только во время обучения.\n\n6. **Импорт библиотек**: Вы импортируете библиотеку os, но не используете ее в коде. Лучше всего удалять неиспользуемые импорты для улучшения читаемости кода.\n\n7. **Логирование**: Вместо простого print лучше использовать модуль logging для более гибкого и контролируемого логирования.\n\n8. **Комментарии**: Ваш код хорошо документирован, но стоит добавить больше комментариев к сложным или неочевидным частям кода.",
    "lines_of_code": 111
  },
  {
    "file": "infer.py",
    "timestamp": "2025-11-19T03:43:28.870478",
    "metrics": {
      "complexity": "infer.py\n    F 10:0 infer_model - A (2)\n",
      "maintainability": "infer.py - A (74.30)\n"
    },
    "ai_recommendations": "В целом, код хорошо написан и следует многим best practices. Однако, есть несколько моментов, которые можно улучшить:\n\n1. **Инициализация модели и токенизатора**: В текущем коде, токенизатор и модель инициализируются каждый раз при вызове функции `infer_model`. Если вы планируете вызывать эту функцию несколько раз, это может привести к ненужным затратам времени на инициализацию. Вместо этого, вы можете инициализировать их один раз вне функции и передавать в качестве аргументов.\n\n2. **Обработка ошибок**: Ваш код не содержит обработки исключений. Что если указанный путь к модели неверен? Или текст для анализа пуст? Хорошей практикой является добавление блоков try/except для обработки возможных ошибок.\n\n3. **Комментарии и документация**: Ваш код содержит некоторые комментарии, но функция `infer_model` не имеет строки документации (docstring), которая объясняла бы, что делает эта функция, что она принимает на вход и что возвращает.\n\n4. **Использование глобальных переменных**: DEVICE является глобальной переменной, что в некоторых случаях может привести к проблемам. Лучше передавать её как аргумент функции.\n\n5. **Производительность**: Если вы работаете с большими объемами данных, может быть полезно использовать `torch.no_grad()`, чтобы временно отключить вычисление градиентов, которые не нужны во время инференса. Это может существенно ускорить процесс и сэкономить память.\n\n6. **Безопасность**: Ваш код не содержит явных угроз безопасности. Однако, стоит убедиться, что используемые библиотеки и зависимости обновлены до последних версий, чтобы избежать возможных уязвимостей.\n\nВот как может выглядеть улучшенная версия кода:\n\n```python\nimport argparse\nimport torch\nfrom transformers import AutoModelForSequenceClassification, AutoTokenizer\n\n# Настройка устройства\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\ndef init_model(model_dir):\n    tokenizer = AutoTokenizer.from_pretrained(model_dir)\n    model = AutoModelForSequenceClassification.from_pretrained(model_dir)\n    model.to(DEVICE)\n    return tokenizer, model\n\ndef infer_model(tokenizer, model, text):\n    \"\"\"\n    Функция для инференса модели.\n    Принимает на вход токенизатор, модель и текст для анализа.\n    Возвращает список вероятностей.\n    \"\"\"\n    tokens = tokenizer(\n        text, return_tensors=\"pt\", truncation=True, padding=True, max_length=128\n    )\n    tokens = {k: v.to(DEVICE) for k, v in tokens.items()}\n\n    model.eval()\n    with torch.no_grad():\n        outputs = model(**tokens)\n        probabilities = torch.softmax(outputs.logits, dim=-1)\n\n    return probabilities.tolist()\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser(description=\"Инференс с медицинской нейросетью\")\n    parser.add_argument(\"--model\", required=True, help=\"Путь к сохраненной модели\")\n    parser.add_argument(\"--text\", required=True, help=\"Текст для анализа\")\n    args = parser.parse_args()\n\n    try:\n        tokenizer, model = init_model(args.model)\n        result = infer_model(tokenizer, model, args.text)\n        print(f\"Результаты предсказания: {result}\")\n    except Exception as e:\n        print(f\"Произошла ошибка: {e}\")\n```",
    "lines_of_code": 35
  },
  {
    "file": "prepare_data.py",
    "timestamp": "2025-11-19T03:43:43.011917",
    "metrics": {
      "complexity": "prepare_data.py\n    F 13:0 prepare_data - A (3)\n",
      "maintainability": "prepare_data.py - A (84.99)\n"
    },
    "ai_recommendations": "В целом, код хорошо структурирован и читаем. Он следует стандартам PEP 8 и использует docstrings для документации функций. Однако есть несколько мест, которые можно улучшить:\n\n1. **Обработка исключений:** Ваш код может вызвать исключение, если CSV-файл не содержит столбцов 'text' и 'label'. Это хорошо, но было бы еще лучше, если бы вы добавили обработку исключений для других возможных ошибок, таких как проблемы с чтением файла или созданием директории.\n\n2. **Логирование:** Ваш код использует логирование, что является хорошей практикой. Однако, вы можете добавить больше информации в ваши логи, например, время выполнения каждого шага. Это поможет вам лучше понять, какие части вашего кода могут быть узкими местами.\n\n3. **Оптимизация:** Ваш код использует pandas для чтения и обработки данных. Это удобно, но может быть неэффективно для больших наборов данных. Если у вас есть проблемы с производительностью, вы можете рассмотреть возможность использования более эффективных библиотек, таких как Dask.\n\n4. **Тестирование:** Ваш код не содержит тестов. Хорошей практикой является написание тестов для проверки корректности работы вашего кода. Вы можете использовать библиотеки, такие как pytest, для написания тестов.\n\n5. **Комментарии:** Ваш код содержит комментарии, которые объясняют, что делает каждый блок кода. Это хорошо, но некоторые комментарии могут быть избыточными. Например, комментарий \"# Разделение данных\" перед вызовом функции train_test_split. Это очевидно из самого вызова функции.",
    "lines_of_code": 53
  },
  {
    "file": "scripts/fix_csv_headers.py",
    "timestamp": "2025-11-19T03:44:09.058818",
    "metrics": {
      "complexity": "",
      "maintainability": "scripts/fix_csv_headers.py - A (90.78)\n"
    },
    "ai_recommendations": "В целом, код написан хорошо и достаточно читаем, но есть несколько моментов, которые можно улучшить:\n\n1. **Чтение и запись в один и тот же файл**: В текущем подходе, сначала файл читается полностью, а затем в него записывается обратно. Если файл будет очень большим, это может привести к проблемам с памятью. Кроме того, если процесс будет прерван во время записи, исходный файл может быть поврежден. Рекомендуется создать временный файл, в который будет производиться запись, а затем заменить исходный файл этим временным файлом.\n\n2. **Использование csv.reader**: Вместо прямого чтения строк и проверки на наличие запятых, можно использовать csv.reader для чтения CSV-файла. Это позволит корректно обрабатывать случаи, когда запятые находятся внутри кавычек.\n\n3. **Обработка ошибок**: В коде нет обработки ошибок, например, если файл не найден или не может быть прочитан. Добавление блока try/except может помочь обработать эти ситуации и предоставить пользователю более понятные сообщения об ошибках.\n\n4. **Использование логгирования вместо print**: Вместо использования print для вывода информации о процессе, лучше использовать стандартный модуль logging. Это позволит более гибко управлять уровнями сообщений и их выводом.\n\n5. **Комментарии и документация**: Хотя код и так достаточно понятен, добавление комментариев к каждому блоку кода или функции, а также общее описание скрипта в начале файла, помогут другим разработчикам быстрее понять, что делает этот код.\n\n6. **Тестирование**: Добавление тестов поможет убедиться, что код работает правильно, и облегчит его дальнейшую поддержку и развитие.",
    "lines_of_code": 29
  }
]