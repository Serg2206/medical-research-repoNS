[
  {
    "file": "train.py",
    "timestamp": "2025-11-25T03:47:16.127486",
    "metrics": {
      "complexity": "train.py\n    F 77:0 train_model - A (4)\n    F 47:0 prepare_data - A (3)\n    C 22:0 MedicalDataset - A (2)\n    M 23:4 MedicalDataset.__init__ - A (1)\n    M 28:4 MedicalDataset.__len__ - A (1)\n    M 31:4 MedicalDataset.__getitem__ - A (1)\n",
      "maintainability": "train.py - A (69.54)\n"
    },
    "ai_recommendations": "В целом, код хорошо написан, но есть несколько моментов, которые можно улучшить:\n\n1. **Обработка ошибок и валидация входных данных**: В функции `prepare_data` есть проверка на наличие необходимых столбцов в CSV-файле, но нет проверки на то, что файл существует и может быть прочитан. Также нет проверки на валидность `output_dir`. Это может привести к неожиданным ошибкам во время выполнения.\n\n2. **Читаемость кода**: Код в целом хорошо организован, но его можно сделать еще более читаемым, разделив функции `prepare_data` и `train_model` на более мелкие функции, каждая из которых выполняет одну конкретную задачу. Это упростит отладку и тестирование.\n\n3. **Производительность**: В функции `train_model` используется метод `model.train()`, который переводит модель в режим обучения. Однако после обучения модель не переводится обратно в режим оценки с помощью `model.eval()`. Это может повлиять на производительность, если модель будет использоваться для предсказаний после обучения.\n\n4. **Best practices**: Вместо использования глобальных переменных `MODEL_NAME` и `DEVICE` лучше передавать их в качестве аргументов функциям, которые их используют. Это делает код более гибким и позволяет легче изменять эти параметры.\n\n5. **Оптимизация использования памяти**: В функции `__getitem__` класса `MedicalDataset` создается тензор для метки с помощью `torch.tensor(item[\"label\"])`. Если метки уже хранятся в формате, подходящем для преобразования в тензор (например, в формате numpy), то можно использовать `torch.from_numpy(item[\"label\"])`, что будет более эффективно с точки зрения использования памяти.\n\n6. **Сохранение прогресса обучения**: В текущей реализации модель сохраняется только после завершения всех эпох обучения. Это может быть проблемой, если процесс обучения длительный и что-то идет не так. Лучше сохранять модель после каждой эпохи или даже после определенного количества шагов внутри эпохи.\n\n7. **Параметры обучения**: В текущей реализации параметры обучения (количество эпох, размер пакета, скорость обучения) захардкожены в функции `train_model`. Лучше сделать их аргументами функции или даже параметрами командной строки, чтобы можно было легко изменять их при запуске скрипта.",
    "lines_of_code": 124
  },
  {
    "file": "main.py",
    "timestamp": "2025-11-25T03:47:43.665869",
    "metrics": {
      "complexity": "main.py\n    F 32:0 train_model - A (4)\n    F 72:0 predict - A (2)\n    C 14:0 MedicalNet - A (2)\n    F 92:0 main - A (1)\n    M 15:4 MedicalNet.__init__ - A (1)\n    M 22:4 MedicalNet.forward - A (1)\n",
      "maintainability": "main.py - A (74.92)\n"
    },
    "ai_recommendations": "В целом, код хорошо структурирован и легко читаем. Однако есть несколько моментов, которые можно улучшить:\n\n1. **Импорты**: В начале файла импортируется модуль `os`, который не используется в коде. Неиспользуемые импорты следует удалять, чтобы улучшить читаемость кода и уменьшить время загрузки модулей.\n\n2. **Комментарии**: Комментарии важны для понимания кода, но в данном случае они кажутся избыточными. Например, комментарий `# Определение архитектуры модели` перед определением класса `MedicalNet` не добавляет никакой дополнительной информации, поскольку из самого кода и так ясно, что здесь определяется архитектура модели.\n\n3. **Обработка ошибок**: В коде отсутствует обработка ошибок. Например, при загрузке модели из файла может возникнуть ошибка, если файл не существует или поврежден. Это можно исправить, добавив блок `try/except` вокруг операции загрузки модели.\n\n4. **Типы данных**: В функциях `train_model` и `predict` данные преобразуются в тензоры PyTorch прямо внутри функций. Это может привести к ошибкам, если эти функции будут вызваны с данными, которые уже являются тензорами. Лучше преобразовывать данные в тензоры перед вызовом этих функций.\n\n5. **Глобальные переменные**: В функции `main` определены переменные `input_size`, `hidden_size` и `output_size`, которые затем передаются в функции `train_model` и `predict`. Это может привести к ошибкам, если эти функции будут вызваны в другом месте кода с другими значениями этих переменных. Лучше определить эти переменные как глобальные константы в начале файла или передать их в функции `train_model` и `predict` как аргументы.\n\n6. **Логирование**: Вместо прямого использования функции `print` для вывода информации о процессе обучения, можно использовать модуль `logging` из стандартной библиотеки Python. Это позволит более гибко управлять выводом информации, например, записывать ее в файл или выводить только сообщения определенного уровня важности.\n\n7. **Сохранение и загрузка модели**: Сейчас модель сохраняется и загружается без указания устройства (cpu или cuda). Это может привести к ошибкам при загрузке модели на устройство, отличное от того, на котором она была обучена. Чтобы избежать этого, можно сохранять и загружать модель следующим образом:\n\n```python\n# Сохранение модели\ntorch.save(model.to('cpu').state_dict(), \"medical_net.pth\")\n\n# Загрузка модели\nmodel = MedicalNet(input_size, hidden_size, output_size)\nmodel.load_state_dict(torch.load(model_path, map_location=device))\nmodel.to(device)\n```\n\n8. **Производительность**: В коде отсутствуют механизмы для отслеживания производительности модели, такие как валидация на отложенной выборке или сохранение модели с лучшим значением функции потерь. Добавление таких механизмов позволит более эффективно контролировать процесс обучения и выбирать наилучшую модель.",
    "lines_of_code": 111
  },
  {
    "file": "infer.py",
    "timestamp": "2025-11-25T03:48:16.000313",
    "metrics": {
      "complexity": "infer.py\n    F 10:0 infer_model - A (2)\n",
      "maintainability": "infer.py - A (74.30)\n"
    },
    "ai_recommendations": "Ваш код в целом хорош, но есть несколько моментов, которые можно улучшить:\n\n1. **Производительность**: Вы загружаете модель и токенизатор каждый раз, когда вызываете функцию `infer_model`. Если вы планируете вызывать эту функцию несколько раз, это может быть неэффективно. Рассмотрите возможность загрузки модели и токенизатора один раз и передачи их в функцию.\n\n2. **Читаемость**: Ваш код хорошо структурирован и читаем, но можно добавить комментарии к функциям и крупным блокам кода для улучшения понимания того, что делает ваш код.\n\n3. **Best practices**: Вместо использования глобальной переменной `DEVICE`, рассмотрите возможность передачи устройства в качестве аргумента функции. Это делает ваш код более гибким и позволяет использовать разные устройства для разных моделей или данных.\n\n4. **Безопасность**: Ваш код в целом безопасен, но всегда стоит быть осторожными при работе с внешними данными, такими как аргументы командной строки. Убедитесь, что вы проверяете и обрабатываете любые возможные исключения, которые могут возникнуть при чтении файлов или обработке данных.\n\nВот как может выглядеть обновленный код:\n\n```python\nimport argparse\nimport torch\nfrom transformers import AutoModelForSequenceClassification, AutoTokenizer\n\ndef load_model_and_tokenizer(model_dir, device):\n    tokenizer = AutoTokenizer.from_pretrained(model_dir)\n    model = AutoModelForSequenceClassification.from_pretrained(model_dir)\n    model.to(device)\n    return model, tokenizer\n\ndef infer_model(model, tokenizer, device, text):\n    tokens = tokenizer(\n        text, return_tensors=\"pt\", truncation=True, padding=True, max_length=128\n    )\n    tokens = {k: v.to(device) for k, v in tokens.items()}\n\n    model.eval()\n    with torch.no_grad():\n        outputs = model(**tokens)\n        probabilities = torch.softmax(outputs.logits, dim=-1)\n\n    return probabilities.tolist()\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser(description=\"Инференс с медицинской нейросетью\")\n    parser.add_argument(\"--model\", required=True, help=\"Путь к сохраненной модели\")\n    parser.add_argument(\"--text\", required=True, help=\"Текст для анализа\")\n    args = parser.parse_args()\n\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model, tokenizer = load_model_and_tokenizer(args.model, device)\n\n    result = infer_model(model, tokenizer, device, args.text)\n    print(f\"Результаты предсказания: {result}\")\n```\n\nТакой подход улучшает производительность, делает код более читаемым и следует лучшим практикам.",
    "lines_of_code": 35
  },
  {
    "file": "prepare_data.py",
    "timestamp": "2025-11-25T03:48:31.283063",
    "metrics": {
      "complexity": "prepare_data.py\n    F 13:0 prepare_data - A (3)\n",
      "maintainability": "prepare_data.py - A (84.99)\n"
    },
    "ai_recommendations": "В целом, код хорошо структурирован и легко читаем. Однако есть несколько моментов, которые можно улучшить:\n\n1. **Обработка ошибок:** В коде есть проверка на наличие необходимых столбцов в CSV-файле, но нет проверки на существование самого файла. Это может привести к неинформативной ошибке, если файл не найден. Рекомендуется добавить проверку на существование файла перед его чтением.\n\n2. **Очистка данных:** В коде есть пример очистки данных, который просто удаляет пробелы в начале и конце каждого текста. Возможно, вам потребуется более сложная очистка данных, включая удаление или замену специальных символов, приведение текста к нижнему регистру и т.д. Рекомендуется определить функцию для очистки данных и применять ее к текстовым данным.\n\n3. **Логирование:** Хотя логирование в целом хорошо настроено, рекомендуется добавить больше информации в логи, включая время выполнения каждого этапа обработки данных. Это поможет вам лучше понять, какие части кода занимают больше всего времени, и оптимизировать их при необходимости.\n\n4. **Тестирование:** В коде нет тестов. Хотя это не всегда обязательно для небольших скриптов, рекомендуется добавить тесты, особенно если вы планируете расширять функциональность этого кода в будущем. Тесты помогут вам убедиться, что ваш код работает правильно после каждого изменения.\n\n5. **Документация:** В коде есть комментарии и строка документации для функции `prepare_data`, но нет общего описания скрипта в начале файла. Рекомендуется добавить краткое описание того, что делает этот скрипт, в начале файла.",
    "lines_of_code": 53
  },
  {
    "file": "scripts/fix_csv_headers.py",
    "timestamp": "2025-11-25T03:48:48.609067",
    "metrics": {
      "complexity": "",
      "maintainability": "scripts/fix_csv_headers.py - A (90.78)\n"
    },
    "ai_recommendations": "В целом, код написан хорошо и читаем, но есть несколько моментов, которые можно улучшить:\n\n1. **Производительность**: Ваш код сначала читает все строки из файла в память, а затем записывает их обратно. Это может быть проблематично для больших файлов, которые не умещаются в память. Вместо этого, вы можете обрабатывать файл построчно, что значительно уменьшит использование памяти.\n\n2. **Безопасность**: Ваш код перезаписывает исходный файл, что может быть опасно, если произойдет ошибка во время обработки. Лучше записывать результаты в новый файл, чтобы сохранить исходные данные.\n\n3. **Читаемость**: Ваш код может быть более читаемым, если вы разделите его на функции. Это также упростит тестирование и повторное использование кода.\n\n4. **Best practices**: Вместо того, чтобы использовать `readlines()` и `writelines()`, лучше использовать встроенный модуль `csv` для чтения и записи CSV-файлов. Это упростит код и сделает его более надежным для работы с CSV-файлами.\n\nВот пример улучшенного кода:\n\n```python\n#!/usr/bin/env python3\n\"\"\"Fix CSV file by removing invalid header rows\"\"\"\n\nimport csv\nimport sys\n\ndef clean_csv(input_file, output_file):\n    with open(input_file, \"r\", encoding=\"utf-8\") as f_in, open(output_file, \"w\", encoding=\"utf-8\") as f_out:\n        reader = csv.reader(f_in)\n        writer = csv.writer(f_out)\n\n        invalid_lines = 0\n        for i, row in enumerate(reader):\n            if i == 0 or len(row) > 1:  # Keep the header row and rows with CSV data\n                writer.writerow(row)\n            else:\n                invalid_lines += 1\n                print(f\"Removing invalid line {i+1}: {','.join(row)}\")\n\n        print(f\"\\nDone! Kept {i+1-invalid_lines} valid lines, removed {invalid_lines} invalid lines\")\n\nif __name__ == \"__main__\":\n    clean_csv(\"training-data/medical_training_data.csv\", \"training-data/cleaned_medical_training_data.csv\")\n```\n\nЭтот код делает то же самое, что и ваш, но он более безопасен, эффективен и легко читаем.",
    "lines_of_code": 29
  }
]