[
  {
    "file": "train.py",
    "timestamp": "2025-11-12T03:43:09.013452",
    "metrics": {
      "complexity": "train.py\n    F 77:0 train_model - A (4)\n    F 47:0 prepare_data - A (3)\n    C 22:0 MedicalDataset - A (2)\n    M 23:4 MedicalDataset.__init__ - A (1)\n    M 28:4 MedicalDataset.__len__ - A (1)\n    M 31:4 MedicalDataset.__getitem__ - A (1)\n",
      "maintainability": "train.py - A (69.54)\n"
    },
    "ai_recommendations": "В целом, код хорошо структурирован и легко читаем. Однако, есть несколько мест, где можно улучшить производительность, безопасность и читаемость.\n\n1. **Читаемость и best practices**: Вместо использования строкового формата для логирования, можно использовать f-строки, которые более читаемы и эффективны. Например, вместо `logger.info(\"Чтение данных из %s\", input_csv)` можно использовать `logger.info(f\"Чтение данных из {input_csv}\")`.\n\n2. **Производительность**: В функции `train_model`, вы загружаете данные из CSV-файла, затем создаете `MedicalDataset` и `DataLoader`. Это может быть довольно медленно для больших наборов данных. Возможно, стоит рассмотреть возможность использования более эффективных методов загрузки данных, таких как `torchtext` или `tf.data`.\n\n3. **Безопасность**: В функции `prepare_data`, вы сохраняете обработанные данные в указанной директории. Однако, вы не проверяете, существует ли эта директория или имеет ли она правильные разрешения. Возможно, стоит добавить проверку на существование директории и ее разрешения перед сохранением данных.\n\n4. **Best practices**: В функции `train_model`, вы используете AdamW в качестве оптимизатора. Это хороший выбор, но вы можете также рассмотреть использование learning rate scheduler, чтобы динамически адаптировать learning rate во время обучения. Это может помочь улучшить производительность модели.\n\n5. **Best practices**: В функции `train_model`, вы сохраняете модель после каждой эпохи. Это может быть неэффективно, если у вас много эпох. Возможно, стоит сохранять модель только после определенного количества эпох или когда достигнута определенная метрика.\n\n6. **Best practices**: В функции `train_model`, вы не используете валидационный набор данных для проверки производительности модели во время обучения. Это может привести к переобучению. Рекомендуется использовать валидационный набор данных и раннюю остановку для предотвращения переобучения.\n\n7. **Читаемость**: Вместо использования `os.path.join`, можно использовать f-строки или pathlib для работы с путями. Это делает код более читаемым и понятным. Например, вместо `os.path.join(output_dir, \"train.csv\")` можно использовать `f\"{output_dir}/train.csv\"` или `Path(output_dir) / \"train.csv\"`.",
    "lines_of_code": 124
  },
  {
    "file": "main.py",
    "timestamp": "2025-11-12T03:43:29.584356",
    "metrics": {
      "complexity": "main.py\n    F 32:0 train_model - A (4)\n    F 72:0 predict - A (2)\n    C 14:0 MedicalNet - A (2)\n    F 92:0 main - A (1)\n    M 15:4 MedicalNet.__init__ - A (1)\n    M 22:4 MedicalNet.forward - A (1)\n",
      "maintainability": "main.py - A (74.92)\n"
    },
    "ai_recommendations": "В целом, код хорошо структурирован и легко читаем. Однако есть несколько моментов, которые можно улучшить:\n\n1. **Импорты**: Импорты должны быть сгруппированы в следующем порядке: стандартные библиотеки, сторонние библиотеки, локальные модули. В данном случае, `os` не используется и его можно удалить.\n\n2. **Документация**: Добавьте комментарии и docstrings к классам и функциям для улучшения читаемости и понимания кода. Это особенно важно для функций `train_model` и `predict`, где могут быть неясными некоторые детали.\n\n3. **Обработка ошибок**: В функции `predict` нет проверки на существование файла модели. Если файла нет, будет сгенерировано исключение. Лучше добавить проверку на существование файла и выдать понятное сообщение об ошибке, если файл отсутствует.\n\n4. **Глобальные переменные**: В функции `main` определены глобальные переменные `input_size`, `hidden_size`, `output_size`. Лучше передавать их как аргументы в функции `train_model` и `predict`.\n\n5. **Жестко заданные параметры**: В функции `train_model` параметры обучения, такие как learning rate и количество эпох, заданы жестко. Лучше сделать их аргументами функции с значениями по умолчанию, чтобы у пользователя была возможность их изменять.\n\n6. **Печать прогресса обучения**: Вместо печати прогресса обучения на каждой эпохе можно использовать индикатор прогресса, например, из библиотеки `tqdm`. Это сделает вывод более наглядным.\n\n7. **Сохранение и загрузка модели**: Лучше передавать путь для сохранения модели как аргумент в функции `train_model`. Аналогично для функции `predict`, путь к модели лучше передавать как аргумент.\n\n8. **Оптимизация производительности**: Вместо использования `torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")` в каждой функции, лучше определить его один раз в начале скрипта и использовать глобально. Это улучшит производительность, особенно при большом количестве вызовов этих функций.\n\n9. **Тестирование**: Добавьте тесты для проверки корректности работы функций и классов.",
    "lines_of_code": 111
  },
  {
    "file": "infer.py",
    "timestamp": "2025-11-12T03:43:53.896907",
    "metrics": {
      "complexity": "infer.py\n    F 10:0 infer_model - A (2)\n",
      "maintainability": "infer.py - A (74.30)\n"
    },
    "ai_recommendations": "Ваш код в целом хорош, но есть несколько мест, которые можно улучшить для повышения производительности, безопасности и читаемости.\n\n1. **Инициализация модели и токенизатора**: Ваша функция `infer_model` каждый раз заново инициализирует модель и токенизатор при каждом вызове. Это может быть довольно затратно по времени и ресурсам, особенно если вы планируете делать много предсказаний. Рекомендуется инициализировать модель и токенизатор один раз, а затем просто использовать их для предсказаний.\n\n2. **Обработка ошибок**: Ваш код не содержит обработку ошибок. Что если указанный путь к модели неверен? Что если текст пустой? Рекомендуется добавить проверки и обработку ошибок для этих сценариев.\n\n3. **Читаемость и структура кода**: Ваш код в целом хорошо структурирован, но его можно улучшить, разделив его на более мелкие функции. Например, вы можете выделить часть кода, отвечающую за обработку входных данных, в отдельную функцию.\n\n4. **Документация**: Ваш код не содержит комментариев или документации. Хорошая практика - это добавление комментариев к коду и документации к функциям, чтобы другие разработчики могли легче понять, что делает ваш код.\n\n5. **Best Practices**: Ваш код не следует некоторым из лучших практик Python. Например, вместо использования глобальной переменной DEVICE, лучше передавать ее как аргумент функции. Это делает ваш код более модульным и упрощает тестирование.\n\n6. **Оптимизация производительности**: Ваш код может быть оптимизирован для улучшения производительности. Например, вы можете использовать `torch.no_grad()` в контексте, чтобы временно отключить вычисление градиентов, что не нужно при инференсе и может ускорить процесс.",
    "lines_of_code": 35
  },
  {
    "file": "prepare_data.py",
    "timestamp": "2025-11-12T03:44:10.960601",
    "metrics": {
      "complexity": "prepare_data.py\n    F 13:0 prepare_data - A (3)\n",
      "maintainability": "prepare_data.py - A (84.99)\n"
    },
    "ai_recommendations": "В целом, код хорошо структурирован, логирование настроено, и код легко читается. Однако есть несколько моментов, которые можно улучшить:\n\n1. **Обработка исключений**: В текущей реализации, если входной CSV-файл не содержит столбцов 'text' и 'label', будет выброшено исключение ValueError. Это хорошо, но можно добавить более подробное сообщение об ошибке, указав, какие столбцы отсутствуют.\n\n2. **Документация**: Функция `prepare_data` хорошо документирована, но можно добавить информацию о типах входных параметров и возвращаемом значении (если оно есть) для улучшения читаемости и понимания кода.\n\n3. **Оптимизация**: В зависимости от размера данных, чтение всего файла сразу может быть неэффективным. Если данные большие, можно рассмотреть возможность чтения файла по частям.\n\n4. **Тестирование**: В коде нет тестов. Хорошей практикой является написание unit-тестов для проверки корректности работы кода.\n\n5. **Жестко заданное значение**: В коде используется жестко заданное значение `random_state=42` в функции `train_test_split`. Это может привести к тому, что разделение данных будет одинаковым при каждом запуске скрипта, что может быть не желательно в некоторых случаях. Если это необходимо для воспроизводимости результатов, стоит это указать в комментариях.\n\n6. **Чистка данных**: В коде есть комментарий \"Очистка данных (пример)\", но не понятно, что именно это означает. Если это место для добавления дополнительной обработки данных, стоит это указать более явно.\n\n7. **Использование argparse**: В текущей реализации скрипта нет возможности изменить размер тестовой выборки через аргументы командной строки. Это можно исправить, добавив соответствующий аргумент в argparse.",
    "lines_of_code": 53
  },
  {
    "file": "scripts/fix_csv_headers.py",
    "timestamp": "2025-11-12T03:44:27.096796",
    "metrics": {
      "complexity": "",
      "maintainability": "scripts/fix_csv_headers.py - A (90.78)\n"
    },
    "ai_recommendations": "В целом, код написан хорошо, но есть несколько моментов, которые можно улучшить:\n\n1. **Производительность**: Вместо того, чтобы сначала считывать все строки из файла, а затем итерироваться по ним, можно считывать и обрабатывать строки по одной. Это снизит потребление памяти, особенно при работе с большими файлами.\n\n2. **Безопасность**: В данном случае, код открывает и изменяет файл без какой-либо защиты от ошибок. Если в процессе записи файла произойдет ошибка, исходный файл может быть поврежден. Лучше сначала записывать данные во временный файл, а затем переименовывать его в исходный файл.\n\n3. **Читаемость**: Вместо использования индекса `i` для проверки первой строки, можно использовать отдельную переменную-флаг, которая будет указывать, является ли текущая строка заголовком.\n\n4. **Best Practices**: Вместо использования `readlines()` и `writelines()`, лучше использовать функции `csv.reader()` и `csv.writer()`. Это сделает код более устойчивым к различным форматам CSV.\n\nВот пример улучшенного кода:\n\n```python\n#!/usr/bin/env python3\n\"\"\"Fix CSV file by removing invalid header rows\"\"\"\n\nimport csv\nimport os\nimport tempfile\nimport sys\n\ninput_file = \"training-data/medical_training_data.csv\"\ntemp_file = tempfile.NamedTemporaryFile(delete=False)\n\n# Read the CSV file and write to a temporary file\nwith open(input_file, \"r\", encoding=\"utf-8\") as csv_file, open(temp_file.name, \"w\", encoding=\"utf-8\") as temp:\n    reader = csv.reader(csv_file)\n    writer = csv.writer(temp)\n\n    for i, row in enumerate(reader):\n        if i == 0 or len(row) > 1:  # Keep the header row and rows with CSV data\n            writer.writerow(row)\n        else:\n            print(f\"Removing invalid line {i+1}: {','.join(row)}\")\n\n# Replace the original file with the cleaned file\nos.replace(temp_file.name, input_file)\n\nprint(f\"\\nDone!\")\n```\n\nВ этом коде мы используем модуль `csv` для чтения и записи CSV-файлов, что делает код более устойчивым к различным форматам CSV. Мы также используем временный файл для записи очищенных данных, чтобы избежать потери исходных данных в случае ошибки.",
    "lines_of_code": 29
  }
]