[
  {
    "file": "train.py",
    "timestamp": "2025-11-17T03:47:15.822836",
    "metrics": {
      "complexity": "train.py\n    F 77:0 train_model - A (4)\n    F 47:0 prepare_data - A (3)\n    C 22:0 MedicalDataset - A (2)\n    M 23:4 MedicalDataset.__init__ - A (1)\n    M 28:4 MedicalDataset.__len__ - A (1)\n    M 31:4 MedicalDataset.__getitem__ - A (1)\n",
      "maintainability": "train.py - A (69.54)\n"
    },
    "ai_recommendations": "В целом, код хорошо структурирован и легко читается. Однако есть несколько моментов, которые можно улучшить:\n\n1. **Обработка ошибок**: В функции `prepare_data` есть проверка на наличие необходимых столбцов в данных. Это хорошо, но можно добавить больше проверок на валидность данных. Например, можно проверить, не пустой ли файл, не содержат ли столбцы 'text' и 'label' пустые значения и т.д.\n\n2. **Использование глобальных переменных**: В коде используются глобальные переменные `MODEL_NAME` и `DEVICE`. Это может привести к проблемам, если код будет использоваться в более сложных проектах. Лучше передавать эти значения в функции в качестве аргументов.\n\n3. **Обучение модели**: В функции `train_model` после каждого батча происходит обнуление градиентов. Это может быть неэффективно, если размер батча мал. Вместо этого можно накапливать градиенты за несколько батчей и затем делать шаг оптимизации.\n\n4. **Сохранение модели**: Модель сохраняется после каждой эпохи обучения. Это может быть неэффективно, если количество эпох большое. Вместо этого можно сохранять модель только после последней эпохи или когда достигается наилучшее качество на валидационной выборке.\n\n5. **Очистка данных**: В функции `prepare_data` происходит очистка данных (удаление пробелов в начале и конце текста). Это может быть недостаточно, в зависимости от данных могут потребоваться дополнительные шаги по очистке и предобработке данных.\n\n6. **Тестирование модели**: В коде нет части, которая бы тестировала модель на тестовых данных после обучения. Это важно для оценки качества модели.\n\n7. **Комментарии**: Хотя большая часть кода хорошо документирована, некоторые функции и классы не имеют комментариев, описывающих их назначение и параметры. Это может затруднить понимание кода другими разработчиками. \n\n8. **Оптимизация использования памяти**: В функции `train_model` данные загружаются в память целиком. Если объем данных велик, это может привести к проблемам с памятью. Вместо этого можно использовать генераторы для чтения и обработки данных по частям.",
    "lines_of_code": 124
  },
  {
    "file": "main.py",
    "timestamp": "2025-11-17T03:47:36.772226",
    "metrics": {
      "complexity": "main.py\n    F 32:0 train_model - A (4)\n    F 72:0 predict - A (2)\n    C 14:0 MedicalNet - A (2)\n    F 92:0 main - A (1)\n    M 15:4 MedicalNet.__init__ - A (1)\n    M 22:4 MedicalNet.forward - A (1)\n",
      "maintainability": "main.py - A (74.92)\n"
    },
    "ai_recommendations": "Ваш код в целом хорошо структурирован и легко читается. Однако, есть несколько моментов, которые можно улучшить:\n\n1. **Импорт библиотек**: Ваш код импортирует модуль `os`, который не используется в коде. Лучше удалить неиспользуемые импорты, чтобы улучшить читаемость и производительность кода.\n\n2. **Комментарии**: Хотя большинство функций и классов имеют комментарии, они не следуют стандарту PEP 257, который рекомендует использовать строки документации (docstrings). Это улучшит читаемость и позволит использовать автоматические инструменты для создания документации.\n\n3. **Обработка ошибок**: Ваш код не обрабатывает ошибки, которые могут возникнуть при загрузке модели в функции `predict`. Возможно, стоит добавить блок `try/except` для обработки возможных исключений.\n\n4. **Жесткое кодирование**: Ваш код содержит жестко закодированные значения, такие как количество эпох, размер батча и скорость обучения. Это может затруднить изменение этих параметров в будущем. Рассмотрите возможность передачи этих значений в качестве аргументов функций.\n\n5. **Оптимизация производительности**: Если вы используете GPU для обучения модели, вы можете ускорить процесс, перемещая данные на GPU пакетами, а не по одному. Это можно сделать, используя метод `DataLoader` с параметром `pin_memory=True`.\n\n6. **Вывод информации во время обучения**: Вместо вывода потерь на каждой эпохе, вы можете рассмотреть возможность использования инструментов визуализации, таких как TensorBoard, для отслеживания процесса обучения в реальном времени.\n\n7. **Сохранение и загрузка модели**: Сохранение всего состояния модели может быть полезным, если вы хотите продолжить обучение позже. Вместо `model.state_dict()`, вы можете сохранить всю модель с помощью `torch.save(model, filepath)`. Затем вы можете загрузить модель с помощью `model = torch.load(filepath)`.",
    "lines_of_code": 111
  },
  {
    "file": "infer.py",
    "timestamp": "2025-11-17T03:48:02.772387",
    "metrics": {
      "complexity": "infer.py\n    F 10:0 infer_model - A (2)\n",
      "maintainability": "infer.py - A (74.30)\n"
    },
    "ai_recommendations": "В целом, код хорошо структурирован и легко читаем. Однако, есть несколько предложений по улучшению:\n\n1. **Импорт модулей**: Рекомендуется группировать импорты в соответствии с PEP8. Сначала идут импорты стандартной библиотеки, затем сторонних библиотек, и в конце - импорты модулей текущего проекта.\n\n2. **Комментарии**: Хотя большинство функций и переменных имеют понятные имена, добавление комментариев к ключевым частям кода может улучшить его читаемость.\n\n3. **Обработка ошибок**: В коде отсутствует обработка исключений. Например, что произойдет, если модель не найдет? Или что, если текстовый аргумент пустой? Рекомендуется добавить обработку исключений для таких сценариев.\n\n4. **Оптимизация использования памяти**: Модель и токенизатор загружаются каждый раз, когда вызывается функция infer_model. Если вы планируете вызывать эту функцию несколько раз, это может быть неэффективно. Рассмотрите возможность загрузки модели и токенизатора один раз и передачи их в функцию как аргументы.\n\n5. **Best Practices**: Вместо использования глобальной переменной DEVICE, рассмотрите возможность передачи ее в качестве аргумента функции. Это делает функцию более универсальной и упрощает тестирование.\n\n6. **Типизация**: Для улучшения читаемости и предсказуемости поведения кода рекомендуется использовать аннотации типов в соответствии с PEP 484.\n\n7. **Принты**: Вместо print лучше использовать логгирование. Это позволит контролировать уровень детализации вывода, а также легче будет отслеживать ошибки и их контекст.\n\nВот пример того, как могут выглядеть некоторые из этих улучшений:\n\n```python\nimport argparse\nimport torch\nfrom transformers import AutoModelForSequenceClassification, AutoTokenizer\n\ndef load_model_and_tokenizer(model_dir: str, device: torch.device):\n    tokenizer = AutoTokenizer.from_pretrained(model_dir)\n    model = AutoModelForSequenceClassification.from_pretrained(model_dir)\n    model.to(device)\n    return model, tokenizer\n\ndef infer_model(model, tokenizer, text: str, device: torch.device):\n    tokens = tokenizer(\n        text, return_tensors=\"pt\", truncation=True, padding=True, max_length=128\n    )\n    tokens = {k: v.to(device) for k, v in tokens.items()}\n\n    model.eval()\n    with torch.no_grad():\n        outputs = model(**tokens)\n        probabilities = torch.softmax(outputs.logits, dim=-1)\n\n    return probabilities.tolist()\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser(description=\"Инференс с медицинской нейросетью\")\n    parser.add_argument(\"--model\", required=True, help=\"Путь к сохраненной модели\")\n    parser.add_argument(\"--text\", required=True, help=\"Текст для анализа\")\n    args = parser.parse_args()\n\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model, tokenizer = load_model_and_tokenizer(args.model, device)\n    result = infer_model(model, tokenizer, args.text, device)\n    print(f\"Результаты предсказания: {result}\")\n```",
    "lines_of_code": 35
  },
  {
    "file": "prepare_data.py",
    "timestamp": "2025-11-17T03:48:22.467340",
    "metrics": {
      "complexity": "prepare_data.py\n    F 13:0 prepare_data - A (3)\n",
      "maintainability": "prepare_data.py - A (84.99)\n"
    },
    "ai_recommendations": "В целом, код хорошо структурирован, легко читаем и следует некоторым best practices. Однако есть несколько мест, которые можно улучшить:\n\n1. **Обработка ошибок**: В коде есть проверка на наличие необходимых столбцов в данных, но нет проверки на существование входного файла или его корректность. Это может привести к неожиданным ошибкам во время выполнения. Лучше добавить проверку на существование файла и его формат.\n\n2. **Очистка данных**: В коде есть пример очистки данных, где удаляются пробелы в начале и конце строки. Возможно, потребуется более сложная предобработка данных, включая удаление или замену специальных символов, приведение текста к нижнему регистру и т.д.\n\n3. **Комментарии**: Хотя большая часть кода достаточно понятна, некоторые строки могут быть не совсем очевидны для новых разработчиков. Например, что делает `os.makedirs(output_dir, exist_ok=True)`? Хорошей практикой является добавление комментариев к таким строкам для улучшения читаемости.\n\n4. **Логирование**: В коде используется логирование, что является хорошей практикой. Однако, можно добавить больше информации в логи, например, время выполнения каждого этапа обработки данных.\n\n5. **Тестирование**: В коде нет тестов. Хорошей практикой является написание тестов для проверки корректности работы кода, особенно при работе с данными.\n\n6. **Аргументы командной строки**: В коде используется argparse для обработки аргументов командной строки. Хорошей практикой является добавление аргумента `--test_size` для указания размера тестовой выборки, вместо использования фиксированного значения.\n\n7. **Сохранение данных**: В коде данные сохраняются в формате CSV. В зависимости от размера данных и требований к производительности, может быть предпочтительнее использовать другой формат, например, Parquet или HDF5.",
    "lines_of_code": 53
  },
  {
    "file": "scripts/fix_csv_headers.py",
    "timestamp": "2025-11-17T03:48:42.827463",
    "metrics": {
      "complexity": "",
      "maintainability": "scripts/fix_csv_headers.py - A (90.78)\n"
    },
    "ai_recommendations": "В целом, код выглядит неплохо и читается довольно легко. Однако есть несколько моментов, которые можно улучшить:\n\n1. **Производительность**: Вместо того, чтобы сначала считывать все строки из файла, а затем фильтровать их, можно сразу же фильтровать строки при чтении. Это сэкономит память, особенно если файл очень большой.\n\n2. **Безопасность**: Нет проверки на наличие файла перед его открытием. Это может привести к ошибке во время выполнения, если файл не существует. Хорошей практикой является обработка таких исключений.\n\n3. **Читаемость и best practices**: Вместо того, чтобы использовать индекс для определения первой строки, можно использовать флаг, который устанавливается в True после обработки первой строки. Это сделает код более читаемым.\n\n4. **Best practices**: Вместо того, чтобы открывать файл для записи и перезаписывать его, лучше сохранить результат в новый файл. Это предотвратит потерю данных, если что-то пойдет не так во время обработки.\n\nВот улучшенная версия кода:\n\n```python\n#!/usr/bin/env python3\n\"\"\"Fix CSV file by removing invalid header rows\"\"\"\n\nimport csv\nimport sys\nimport os\n\ninput_file = \"training-data/medical_training_data.csv\"\noutput_file = \"training-data/cleaned_medical_training_data.csv\"\n\n# Check if file exists\nif not os.path.isfile(input_file):\n    print(f\"File {input_file} does not exist.\")\n    sys.exit()\n\nvalid_lines = []\ninvalid_lines = 0\nis_header = True\n\n# Read the CSV file and filter out invalid lines\nwith open(input_file, \"r\", encoding=\"utf-8\") as f:\n    for i, line in enumerate(f):\n        if is_header or \",\" in line:  # Keep the header and valid lines\n            valid_lines.append(line)\n            is_header = False\n        else:\n            invalid_lines += 1\n            print(f\"Removing invalid line {i+1}: {line.strip()}\")\n\n# Write back the cleaned CSV\nwith open(output_file, \"w\", encoding=\"utf-8\") as f:\n    f.writelines(valid_lines)\n\nprint(\n    f\"\\nDone! Kept {len(valid_lines)} valid lines, removed {invalid_lines} invalid lines\"\n)\n```\n",
    "lines_of_code": 29
  }
]