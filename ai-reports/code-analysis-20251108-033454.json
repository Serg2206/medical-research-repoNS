[
  {
    "file": "train.py",
    "timestamp": "2025-11-08T03:33:36.837855",
    "metrics": {
      "complexity": "train.py\n    F 77:0 train_model - A (4)\n    F 47:0 prepare_data - A (3)\n    C 22:0 MedicalDataset - A (2)\n    M 23:4 MedicalDataset.__init__ - A (1)\n    M 28:4 MedicalDataset.__len__ - A (1)\n    M 31:4 MedicalDataset.__getitem__ - A (1)\n",
      "maintainability": "train.py - A (69.54)\n"
    },
    "ai_recommendations": "Ваш код в целом хорошо структурирован и легко читаем. Однако, есть несколько моментов, которые можно улучшить:\n\n1. **Обработка ошибок:** В функции `prepare_data` вы проверяете наличие столбцов 'text' и 'label' в данных. Это хорошо, но было бы еще лучше, если бы вы добавили более подробное сообщение об ошибке, чтобы пользователь знал, как исправить проблему.\n\n2. **Чистка данных:** В функции `prepare_data` вы очищаете текст, удаляя пробелы в начале и конце каждой строки. Это хорошая практика, но может быть недостаточно. Возможно, вам стоит добавить дополнительные шаги по очистке данных, такие как преобразование текста к нижнему регистру, удаление специальных символов и т.д.\n\n3. **Оптимизация производительности:** В функции `train_model` вы используете `DataLoader` для загрузки данных. Это хорошо, но вы можете улучшить производительность, используя многопоточную загрузку данных с помощью параметра `num_workers` в `DataLoader`.\n\n4. **Сохранение прогресса обучения:** Ваш код не сохраняет прогресс обучения. Если процесс обучения прерывается, вам придется начинать все сначала. Рассмотрите возможность сохранения прогресса обучения после каждой эпохи, чтобы вы могли возобновить обучение с того места, где оно было прервано.\n\n5. **Параметры обучения:** Ваши параметры обучения (например, количество эпох, размер пакета и скорость обучения) зашиты в коде. Хотя это не всегда плохо, но может быть полезно сделать эти параметры настраиваемыми, чтобы вы могли легко экспериментировать с разными значениями.\n\n6. **Обработка устройства:** Вы используете `torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")` для определения устройства для обучения. Это хорошо, но было бы еще лучше, если бы вы добавили возможность пользователю явно указывать устройство через аргументы командной строки.\n\n7. **Best Practices:** Ваш код не следует некоторым best practices для PyTorch. Например, перед вызовом `loss.backward()` и `optimizer.step()`, рекомендуется вызывать `model.zero_grad()`, а не `optimizer.zero_grad()`. Это обеспечивает, что градиенты обнуляются перед каждым шагом обучения, что может помочь предотвратить накопление градиентов и улучшить производительность обучения.\n\n8. **Комментарии:** Ваш код содержит некоторые комментарии, но они могут быть более подробными. Хорошая практика - комментировать не только то, что делает ваш код, но и почему он это делает. Это может помочь другим разработчикам (или вам в будущем) лучше понять ваш код.",
    "lines_of_code": 124
  },
  {
    "file": "main.py",
    "timestamp": "2025-11-08T03:33:56.691788",
    "metrics": {
      "complexity": "main.py\n    F 32:0 train_model - A (4)\n    F 72:0 predict - A (2)\n    C 14:0 MedicalNet - A (2)\n    F 92:0 main - A (1)\n    M 15:4 MedicalNet.__init__ - A (1)\n    M 22:4 MedicalNet.forward - A (1)\n",
      "maintainability": "main.py - A (74.92)\n"
    },
    "ai_recommendations": "В целом, код написан хорошо и читаемо. Однако, есть несколько моментов, которые можно улучшить:\n\n1. Импорты: Вместо импортирования всего модуля, лучше импортировать только те функции, которые действительно используются. Это улучшит производительность и уменьшит использование памяти.\n\n2. Комментарии: Хотя в коде есть комментарии, некоторые из них не совсем точны или не несут полезной информации. Хорошая практика - это писать комментарии, которые объясняют, почему определенный код написан именно так, а не что он делает.\n\n3. Обработка ошибок: В коде отсутствует обработка ошибок. Это может привести к непредсказуемым результатам и сложностям при отладке. Например, если файл модели не найден, функция `torch.load()` вызовет исключение.\n\n4. Жесткое кодирование: В коде есть жестко закодированные значения, такие как размеры входного, скрытого и выходного слоя, количество эпох, размер пакета и т.д. Лучше сделать эти значения параметрами функций или конфигурационными переменными.\n\n5. Использование GPU: Код проверяет, доступно ли GPU, и если да, то использует его. Однако, это может быть не всегда оптимально, особенно если GPU занято другими задачами. Лучше сделать использование GPU опциональным.\n\n6. Сохранение и загрузка модели: Сейчас модель сохраняется и загружается из жестко закодированного пути. Лучше сделать этот путь параметром функций, чтобы можно было легко изменить место сохранения и загрузки модели.\n\n7. Вывод информации о процессе обучения: Вывод информации о процессе обучения (такой как потери на каждой эпохе) может быть полезен для отладки и оптимизации, но в продакшен-среде он может быть нежелательным. Лучше добавить параметр, который позволяет включать или отключать вывод этой информации.\n\n8. Оптимизация: Вместо использования стандартного оптимизатора Adam, можно попробовать другие оптимизаторы или даже комбинацию оптимизаторов для улучшения производительности модели.",
    "lines_of_code": 111
  },
  {
    "file": "infer.py",
    "timestamp": "2025-11-08T03:34:21.386037",
    "metrics": {
      "complexity": "infer.py\n    F 10:0 infer_model - A (2)\n",
      "maintainability": "infer.py - A (74.30)\n"
    },
    "ai_recommendations": "В целом, код хорошо структурирован и легко читается. Однако, есть несколько моментов, которые можно улучшить:\n\n1. **Производительность**: Модель и токенизатор загружаются при каждом вызове функции `infer_model`. Если вы планируете вызывать эту функцию многократно, это может привести к значительным задержкам. Чтобы улучшить производительность, вы можете загрузить модель и токенизатор один раз вне функции и передавать их в качестве аргументов.\n\n2. **Читаемость**: Вместо того, чтобы использовать словарное включение для переноса токенов на устройство, лучше использовать цикл for. Это улучшит читаемость кода.\n\n3. **Best Practices**: Вместо использования глобальной переменной DEVICE, лучше передавать устройство в качестве аргумента функции. Это делает функцию более универсальной и упрощает тестирование.\n\n4. **Безопасность**: В этом коде нет явных проблем с безопасностью. Однако, всегда стоит быть осторожным при работе с внешними входами, такими как аргументы командной строки. В данном случае, входные данные не проверяются перед использованием, что может привести к ошибкам при некорректных входных данных.\n\nВот как можно улучшить код с учетом этих рекомендаций:\n\n```python\nimport argparse\nimport torch\nfrom transformers import AutoModelForSequenceClassification, AutoTokenizer\n\ndef load_model_and_tokenizer(model_dir, device):\n    tokenizer = AutoTokenizer.from_pretrained(model_dir)\n    model = AutoModelForSequenceClassification.from_pretrained(model_dir)\n    model.to(device)\n    return model, tokenizer\n\ndef infer_model(model, tokenizer, device, text):\n    tokens = tokenizer(\n        text, return_tensors=\"pt\", truncation=True, padding=True, max_length=128\n    )\n    for k, v in tokens.items():\n        tokens[k] = v.to(device)\n\n    model.eval()\n    with torch.no_grad():\n        outputs = model(**tokens)\n        probabilities = torch.softmax(outputs.logits, dim=-1)\n\n    return probabilities.tolist()\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser(description=\"Инференс с медицинской нейросетью\")\n    parser.add_argument(\"--model\", required=True, help=\"Путь к сохраненной модели\")\n    parser.add_argument(\"--text\", required=True, help=\"Текст для анализа\")\n    args = parser.parse_args()\n\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model, tokenizer = load_model_and_tokenizer(args.model, device)\n\n    result = infer_model(model, tokenizer, device, args.text)\n    print(f\"Результаты предсказания: {result}\")\n```\n",
    "lines_of_code": 35
  },
  {
    "file": "prepare_data.py",
    "timestamp": "2025-11-08T03:34:36.965664",
    "metrics": {
      "complexity": "prepare_data.py\n    F 13:0 prepare_data - A (3)\n",
      "maintainability": "prepare_data.py - A (84.99)\n"
    },
    "ai_recommendations": "В целом, код хорошо структурирован и легко читаем. Однако есть несколько областей, где можно внести улучшения:\n\n1. **Обработка исключений:** В данный момент, если входной CSV-файл не содержит столбцов 'text' или 'label', код просто поднимает ValueError. Это может быть не очень информативно для пользователя. Вместо этого, можно добавить более подробное сообщение об ошибке, указывающее, какой именно столбец отсутствует.\n\n2. **Читаемость:** Код может быть более читаемым, если добавить больше комментариев, особенно в тех местах, где происходят сложные операции. Например, в строке, где происходит разделение данных на обучающую и тестовую выборки, можно добавить комментарий, объясняющий, что делает функция `train_test_split`.\n\n3. **Оптимизация:** Вместо использования `os.path.join` для создания пути к файлу, можно использовать f-строки, которые обычно работают быстрее.\n\n4. **Безопасность:** Если входные данные содержат чувствительную информацию, то логирование пути к файлу может представлять собой риск безопасности. Вместо этого, можно просто логировать факт чтения данных.\n\n5. **Best Practices:** Вместо использования \"магического числа\" 42 в качестве `random_state` в `train_test_split`, лучше вынести его в константу в начале файла, чтобы было понятно, что это и зачем оно нужно.\n\n6. **Тестирование:** В коде отсутствуют юнит-тесты, которые могли бы обеспечить его корректность. Рекомендуется добавить тесты, особенно для функции `prepare_data`.",
    "lines_of_code": 53
  },
  {
    "file": "scripts/fix_csv_headers.py",
    "timestamp": "2025-11-08T03:34:54.127437",
    "metrics": {
      "complexity": "",
      "maintainability": "scripts/fix_csv_headers.py - A (90.78)\n"
    },
    "ai_recommendations": "1. **Производительность**: Вместо того, чтобы сначала считывать все строки из файла в память, а затем проходить по ним, можно сразу же фильтровать строки при чтении. Это будет особенно полезно для больших файлов, которые могут не поместиться в память.\n\n2. **Безопасность**: Скрипт перезаписывает исходный файл, что может быть нежелательно, если что-то пойдет не так. Лучше записывать результаты в новый файл.\n\n3. **Читаемость**: Вместо того, чтобы использовать условие `if i == 0` для сохранения заголовка, можно просто добавить заголовок в `valid_lines` до цикла. Это упростит цикл и сделает код более читаемым.\n\n4. **Best practices**: Использование модуля `csv` для работы с CSV-файлами обеспечит более надежную обработку данных.\n\nВот улучшенная версия скрипта:\n\n```python\n#!/usr/bin/env python3\n\"\"\"Fix CSV file by removing invalid header rows\"\"\"\n\nimport csv\nimport sys\n\ninput_file = \"training-data/medical_training_data.csv\"\noutput_file = \"training-data/cleaned_medical_training_data.csv\"\n\n# Read the CSV file and filter out lines that don't have proper CSV structure\n# Invalid lines are those that don't contain commas (are just section headers)\nvalid_lines = []\nwith open(input_file, \"r\", encoding=\"utf-8\") as f:\n    reader = csv.reader(f)\n    for i, line in enumerate(reader):\n        if i == 0 or \",\" in line:  # Keep the header row and lines with CSV data\n            valid_lines.append(line)\n        else:\n            print(f\"Removing invalid line {i+1}: {','.join(line)}\")\n\n# Write back the cleaned CSV\nwith open(output_file, \"w\", encoding=\"utf-8\") as f:\n    writer = csv.writer(f)\n    writer.writerows(valid_lines)\n\nprint(\n    f\"\\nDone! Kept {len(valid_lines)} valid lines, removed {i+1 - len(valid_lines)} invalid lines\"\n)\n```\n\nЭтот скрипт сразу же фильтрует строки при чтении, записывает результаты в новый файл и использует модуль `csv` для работы с CSV-файлами.",
    "lines_of_code": 29
  }
]