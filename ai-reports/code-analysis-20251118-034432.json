[
  {
    "file": "train.py",
    "timestamp": "2025-11-18T03:43:13.464503",
    "metrics": {
      "complexity": "train.py\n    F 77:0 train_model - A (4)\n    F 47:0 prepare_data - A (3)\n    C 22:0 MedicalDataset - A (2)\n    M 23:4 MedicalDataset.__init__ - A (1)\n    M 28:4 MedicalDataset.__len__ - A (1)\n    M 31:4 MedicalDataset.__getitem__ - A (1)\n",
      "maintainability": "train.py - A (69.54)\n"
    },
    "ai_recommendations": "В целом, код хорошо структурирован и легко читается. Однако, есть несколько моментов, которые можно улучшить:\n\n1. **Обработка ошибок и валидация входных данных**: В функции `prepare_data` есть проверка на наличие необходимых столбцов в CSV-файле, но нет проверки на то, что файл вообще существует и может быть прочитан. Это может привести к неинформативным ошибкам и сложностям в отладке.\n\n2. **Читаемость кода**: В функции `__getitem__` в классе `MedicalDataset` создание токенов и возвращение результата можно разделить на два отдельных шага для улучшения читаемости.\n\n3. **Оптимизация использования памяти**: В функции `train_model` данные загружаются в память полностью. Если датасет большой, это может вызвать проблемы с памятью. Рекомендуется использовать генераторы или итераторы для чтения данных.\n\n4. **Оптимизация производительности**: В функции `train_model` после каждого шага градиенты обнуляются. Это может быть неэффективно, если размер батча мал. Вместо этого, можно обнулять градиенты после каждой эпохи.\n\n5. **Безопасность**: В функции `prepare_data` создается директория без проверки на ее существование. Если директория уже существует, это может привести к неожиданным результатам. Лучше добавить проверку на существование директории.\n\n6. **Best practices**: В функции `train_model` модель сохраняется после каждой эпохи. Это может быть неэффективно, если количество эпох большое. Вместо этого, можно сохранять модель только после последней эпохи.\n\n7. **Best practices**: В функции `train_model` используется фиксированный learning rate. Вместо этого, можно использовать один из методов изменения learning rate в процессе обучения (например, learning rate decay).\n\n8. **Best practices**: В функции `train_model` используется фиксированное количество эпох для обучения. Вместо этого, можно использовать early stopping для автоматического останова обучения, когда модель перестает улучшаться.",
    "lines_of_code": 124
  },
  {
    "file": "main.py",
    "timestamp": "2025-11-18T03:43:39.240905",
    "metrics": {
      "complexity": "main.py\n    F 32:0 train_model - A (4)\n    F 72:0 predict - A (2)\n    C 14:0 MedicalNet - A (2)\n    F 92:0 main - A (1)\n    M 15:4 MedicalNet.__init__ - A (1)\n    M 22:4 MedicalNet.forward - A (1)\n",
      "maintainability": "main.py - A (74.92)\n"
    },
    "ai_recommendations": "В целом, код написан хорошо, но есть несколько мест, которые можно улучшить для повышения производительности, читаемости и соблюдения best practices:\n\n1. **Импорты**: В начале файла импортируется модуль `os`, который не используется в коде. Лишние импорты ухудшают читаемость и могут замедлить время загрузки скрипта.\n\n2. **Документация**: В коде отсутствуют комментарии и docstrings, которые могли бы помочь другим разработчикам понять, что делает каждая функция и как работает класс. Это ухудшает читаемость и поддерживаемость кода.\n\n3. **Обработка ошибок**: В функции `predict` загружается модель из файла, но нет обработки ошибок на случай, если файл не найден или поврежден. Это может привести к непредсказуемым ошибкам во время выполнения.\n\n4. **Глобальные переменные**: В функции `main` определены глобальные переменные `input_size`, `hidden_size` и `output_size`, которые затем передаются в функции `train_model` и `predict`. Это ухудшает читаемость и поддерживаемость кода. Лучше определить эти переменные внутри каждой функции или сделать их аргументами класса `MedicalNet`.\n\n5. **Жесткое кодирование**: В функции `train_model` жестко закодирована скорость обучения (`lr=0.001`). Лучше сделать этот параметр аргументом функции, чтобы можно было легко его изменять.\n\n6. **Повторяющийся код**: В функциях `train_model` и `predict` есть повторяющийся код для определения устройства (`device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")`). Лучше вынести этот код в отдельную функцию.\n\n7. **Сохранение и загрузка модели**: Сохранение и загрузка модели происходит в разных функциях. Это может привести к ошибкам, если путь к файлу модели изменится в одной из функций, но не изменится в другой. Лучше сделать путь к файлу модели аргументом этих функций или определить его в глобальной переменной.\n\n8. **Отсутствие валидации**: Во время обучения модели нет валидации на отложенной выборке, поэтому сложно оценить, насколько хорошо модель обобщает данные. Лучше добавить валидацию в процесс обучения.\n\n9. **Отсутствие логирования**: В коде нет логирования, что затрудняет отладку и мониторинг процесса обучения. Лучше добавить логирование с использованием модуля `logging` из стандартной библиотеки Python.",
    "lines_of_code": 111
  },
  {
    "file": "infer.py",
    "timestamp": "2025-11-18T03:43:59.656295",
    "metrics": {
      "complexity": "infer.py\n    F 10:0 infer_model - A (2)\n",
      "maintainability": "infer.py - A (74.30)\n"
    },
    "ai_recommendations": "В целом, ваш код уже хорошо структурирован и читаем. Однако, есть несколько мест, которые можно улучшить:\n\n1. **Производительность**: Ваша функция `infer_model` каждый раз загружает модель и токенизатор при вызове. Если вы планируете вызывать эту функцию несколько раз, это может быть неэффективно. Вместо этого, вы можете загрузить модель и токенизатор один раз, а затем передавать их в функцию.\n\n2. **Читаемость**: Ваш код уже хорошо структурирован, но вы можете добавить больше комментариев, чтобы объяснить, что делает каждый блок кода. Это поможет другим разработчикам быстрее понять ваш код.\n\n3. **Best practices**: Вместо прямого использования `print` для вывода результатов, рассмотрите возможность использования стандартного модуля `logging`. Это позволит вам более гибко управлять уровнем детализации сообщений, которые вы хотите выводить, и куда вы хотите их выводить (например, в файл или в консоль).\n\n4. **Безопасность**: Ваш код не содержит явных проблем с безопасностью. Однако, стоит учесть, что если текст, который вы передаете в модель, приходит из ненадежного источника, он может содержать вредоносные данные. В этом случае, стоит добавить некоторую форму валидации или очистки данных.\n\nВот как может выглядеть улучшенный код:\n\n```python\nimport argparse\nimport logging\nimport torch\nfrom transformers import AutoModelForSequenceClassification, AutoTokenizer\n\nlogging.basicConfig(level=logging.INFO)\n\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\ndef load_model_and_tokenizer(model_dir):\n    tokenizer = AutoTokenizer.from_pretrained(model_dir)\n    model = AutoModelForSequenceClassification.from_pretrained(model_dir)\n    model.to(DEVICE)\n    return model, tokenizer\n\ndef infer_model(model, tokenizer, text):\n    tokens = tokenizer(\n        text, return_tensors=\"pt\", truncation=True, padding=True, max_length=128\n    )\n    tokens = {k: v.to(DEVICE) for k, v in tokens.items()}\n\n    model.eval()\n    with torch.no_grad():\n        outputs = model(**tokens)\n        probabilities = torch.softmax(outputs.logits, dim=-1)\n\n    return probabilities.tolist()\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser(description=\"Инференс с медицинской нейросетью\")\n    parser.add_argument(\"--model\", required=True, help=\"Путь к сохраненной модели\")\n    parser.add_argument(\"--text\", required=True, help=\"Текст для анализа\")\n    args = parser.parse_args()\n\n    model, tokenizer = load_model_and_tokenizer(args.model)\n    result = infer_model(model, tokenizer, args.text)\n    logging.info(f\"Результаты предсказания: {result}\")\n```",
    "lines_of_code": 35
  },
  {
    "file": "prepare_data.py",
    "timestamp": "2025-11-18T03:44:15.495229",
    "metrics": {
      "complexity": "prepare_data.py\n    F 13:0 prepare_data - A (3)\n",
      "maintainability": "prepare_data.py - A (84.99)\n"
    },
    "ai_recommendations": "В целом, код хорошо структурирован и читаем. Он следует стандартным практикам Python и включает в себя подробные комментарии и строки документации. Однако есть несколько областей, которые можно улучшить:\n\n1. **Обработка исключений**: В настоящее время, если CSV-файл не содержит необходимых столбцов, код просто вызывает исключение ValueError. Это может быть не очень информативно для конечного пользователя. Вместо этого, можно добавить более подробное сообщение об ошибке, которое объяснит, какие столбцы отсутствуют.\n\n2. **Оптимизация чтения данных**: Если CSV-файл очень большой, чтение всего файла в память с помощью `pd.read_csv` может быть неэффективным. Вместо этого, можно использовать параметр `chunksize` функции `pd.read_csv`, чтобы читать файл по частям.\n\n3. **Проверка существования файла и директории**: Прежде чем попытаться прочитать файл или записать в директорию, стоит проверить, существуют ли они. Если нет, то можно бросить исключение с понятным сообщением об ошибке.\n\n4. **Аргументы командной строки**: В настоящее время, `test_size` захардкожен в функции `prepare_data`. Было бы полезно сделать это значение настраиваемым через аргументы командной строки.\n\n5. **Логирование**: Хотя логирование уже настроено, можно добавить больше информации в логи, например, время выполнения каждого шага. Это может быть полезно для отладки и оптимизации производительности.\n\n6. **Тестирование**: Код не содержит тестов. Хорошей практикой является написание модульных тестов для проверки корректности работы кода.\n\n7. **Комментарии**: Хотя большинство функций и блоков кода имеют комментарии, некоторые из них (например, \"Очистка данных (пример)\") могут быть более подробными.",
    "lines_of_code": 53
  },
  {
    "file": "scripts/fix_csv_headers.py",
    "timestamp": "2025-11-18T03:44:32.202092",
    "metrics": {
      "complexity": "",
      "maintainability": "scripts/fix_csv_headers.py - A (90.78)\n"
    },
    "ai_recommendations": "В целом, код написан хорошо, но есть несколько моментов, которые можно улучшить:\n\n1. **Производительность**: Вместо того, чтобы сначала считывать все строки в память, а затем фильтровать их, можно сделать это в один проход. Это особенно важно для больших файлов, которые могут не поместиться в память.\n\n2. **Безопасность**: Ваш код перезаписывает исходный файл, что может быть опасно. Если в процессе что-то пойдет не так, исходные данные могут быть потеряны. Лучше записывать результат в новый файл.\n\n3. **Читаемость и best practices**: Вместо того, чтобы использовать индекс `i` для проверки первой строки, можно просто сначала добавить первую строку в `valid_lines`, а затем продолжить цикл со второй строки. Это улучшит читаемость кода.\n\nВот улучшенная версия кода:\n\n```python\n#!/usr/bin/env python3\n\"\"\"Fix CSV file by removing invalid header rows\"\"\"\n\nimport csv\nimport sys\n\n# Open the CSV file\nwith open(\"training-data/medical_training_data.csv\", \"r\", encoding=\"utf-8\") as f_in, \\\n     open(\"training-data/cleaned_medical_training_data.csv\", \"w\", encoding=\"utf-8\") as f_out:\n    # Read the header\n    header = next(f_in)\n    f_out.write(header)\n\n    valid_lines = 1  # Count the header as a valid line\n    invalid_lines = 0\n\n    # Filter out lines that don't have proper CSV structure\n    for i, line in enumerate(f_in, start=2):  # Start enumeration from 2 because we already read the header\n        if \",\" in line:  # Only keep lines with CSV data\n            f_out.write(line)\n            valid_lines += 1\n        else:\n            print(f\"Removing invalid line {i}: {line.strip()}\")\n            invalid_lines += 1\n\nprint(\n    f\"\\nDone! Kept {valid_lines} valid lines, removed {invalid_lines} invalid lines\"\n)\n```\n\nЭтот код делает то же самое, что и исходный, но он более эффективен, безопасен и читаем.",
    "lines_of_code": 29
  }
]