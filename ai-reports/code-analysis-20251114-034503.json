[
  {
    "file": "train.py",
    "timestamp": "2025-11-14T03:43:34.308616",
    "metrics": {
      "complexity": "train.py\n    F 77:0 train_model - A (4)\n    F 47:0 prepare_data - A (3)\n    C 22:0 MedicalDataset - A (2)\n    M 23:4 MedicalDataset.__init__ - A (1)\n    M 28:4 MedicalDataset.__len__ - A (1)\n    M 31:4 MedicalDataset.__getitem__ - A (1)\n",
      "maintainability": "train.py - A (69.54)\n"
    },
    "ai_recommendations": "В целом, код хорошо структурирован, легко читаем и следует best practices. Однако есть несколько мест, которые можно улучшить:\n\n1. **Обработка исключений**: В функции `prepare_data` есть проверка на наличие столбцов 'text' и 'label' в данных. Если этих столбцов нет, то выбрасывается исключение. Это хорошо, но можно добавить больше контекста в сообщение об ошибке, например, указать, какие столбцы на самом деле присутствуют в данных.\n\n2. **Очистка данных**: В функции `prepare_data` происходит очистка данных с помощью `str.strip()`. Это удаляет лишние пробелы в начале и конце каждой строки. Возможно, вам стоит добавить дополнительные шаги по очистке данных, в зависимости от того, что именно вы ожидаете увидеть в ваших данных.\n\n3. **Константы**: Константы `MODEL_NAME`, `DEVICE` и другие находятся в глобальной области видимости. Лучше перенести их в функцию `main` или в функции, где они используются, чтобы уменьшить глобальное пространство имен.\n\n4. **Документация**: Добавьте больше комментариев и строк документации (docstrings) в ваш код. Это поможет другим разработчикам быстрее понять, что делает ваш код.\n\n5. **Использование GPU**: Ваш код автоматически использует GPU, если он доступен. Это обычно хорошая идея, но иногда вы можете захотеть иметь возможность контролировать это (например, если у вас есть несколько GPU и вы хотите выбрать, какой использовать).\n\n6. **Обучение модели**: В функции `train_model` вы используете AdamW в качестве оптимизатора без какой-либо стратегии уменьшения скорости обучения (learning rate scheduling). Возможно, стоит рассмотреть добавление стратегии уменьшения скорости обучения для улучшения производительности модели.\n\n7. **Сохранение модели**: В конце обучения вы сохраняете модель и токенизатор в одну и ту же директорию. Это может вызвать проблемы, если вы захотите сохранить несколько различных моделей в одну и ту же директорию. Рассмотрите возможность использования отдельных поддиректорий для каждой модели.",
    "lines_of_code": 124
  },
  {
    "file": "main.py",
    "timestamp": "2025-11-14T03:43:48.962925",
    "metrics": {
      "complexity": "main.py\n    F 32:0 train_model - A (4)\n    F 72:0 predict - A (2)\n    C 14:0 MedicalNet - A (2)\n    F 92:0 main - A (1)\n    M 15:4 MedicalNet.__init__ - A (1)\n    M 22:4 MedicalNet.forward - A (1)\n",
      "maintainability": "main.py - A (74.92)\n"
    },
    "ai_recommendations": "В целом, код написан хорошо и следует стандартам Python и PyTorch. Однако, есть несколько мест, которые можно улучшить:\n\n1. **Импорты**: Импорт `os` не используется в коде, его можно удалить. \n\n2. **Документация**: Ваш код не содержит комментариев или docstrings, которые бы объясняли, что делает каждая функция и класс. Это может затруднить понимание кода другими разработчиками.\n\n3. **Обработка ошибок**: Ваш код не содержит обработку исключений, что может привести к непредсказуемым ошибкам во время выполнения. Например, при загрузке модели из файла, файл может быть поврежден или отсутствовать.\n\n4. **Жесткое кодирование**: Размеры входного, скрытого и выходного слоя, а также количество эпох и размер пакета жестко закодированы в функциях `train_model` и `predict`. Это делает ваш код менее гибким. Рекомендуется передавать эти параметры как аргументы функций.\n\n5. **Производительность**: Ваш код не использует возможности параллельной обработки данных, которые предоставляет PyTorch. Вы можете использовать `DataLoader` с параметром `num_workers > 0` для ускорения загрузки данных.\n\n6. **Тестирование**: Ваш код не содержит тестов, которые бы проверяли корректность работы функций и классов. \n\n7. **Логирование**: Вместо простого `print` для вывода информации о процессе обучения, можно использовать более продвинутые инструменты логирования, такие как `logging` в Python или `tensorboard` в PyTorch.\n\n8. **Сохранение и загрузка модели**: Ваш код сохраняет и загружает только параметры модели. Это может вызвать проблемы, если архитектура модели изменится. Рекомендуется сохранять и загружать всю модель, используя `torch.save(model, filepath)` и `model = torch.load(filepath)`.",
    "lines_of_code": 111
  },
  {
    "file": "infer.py",
    "timestamp": "2025-11-14T03:44:33.861727",
    "metrics": {
      "complexity": "infer.py\n    F 10:0 infer_model - A (2)\n",
      "maintainability": "infer.py - A (74.30)\n"
    },
    "ai_recommendations": "В целом, код хорошо написан и следует большинству best practices. Однако есть несколько мест, которые можно улучшить:\n\n1. **Производительность**: Модель и токенизатор загружаются при каждом вызове функции `infer_model`. Если вы планируете использовать эту функцию несколько раз в одной сессии, рекомендуется загрузить модель и токенизатор один раз и затем передавать их в функцию. Это уменьшит накладные расходы на загрузку модели и токенизатора при каждом вызове функции.\n\n2. **Читаемость**: Вместо того, чтобы использовать `**tokens` в вызове модели, лучше явно указать, что вы передаете в модель. Это улучшит читаемость кода и сделает его более понятным для других разработчиков.\n\n3. **Best Practices**: Вместо того, чтобы использовать `print` для вывода результатов, рекомендуется использовать стандартный логгер Python. Это позволит вам более гибко управлять выводом и, если потребуется, легко перенаправить вывод в файл или другой поток.\n\n4. **Безопасность**: В этом коде нет явных проблем с безопасностью. Однако стоит отметить, что важно всегда проверять входные данные на предмет возможных атак (например, SQL-инъекций или XSS-атак), особенно если этот код будет использоваться в веб-приложении.\n\nВот как может выглядеть улучшенный код:\n\n```python\nimport argparse\nimport logging\nimport torch\nfrom transformers import AutoModelForSequenceClassification, AutoTokenizer\n\n# Настройка устройства\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Настройка логгера\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\ndef load_model_and_tokenizer(model_dir):\n    tokenizer = AutoTokenizer.from_pretrained(model_dir)\n    model = AutoModelForSequenceClassification.from_pretrained(model_dir)\n    model.to(DEVICE)\n    return model, tokenizer\n\ndef infer_model(model, tokenizer, text):\n    tokens = tokenizer(\n        text, return_tensors=\"pt\", truncation=True, padding=True, max_length=128\n    )\n    tokens = {k: v.to(DEVICE) for k, v in tokens.items()}\n\n    model.eval()\n    with torch.no_grad():\n        outputs = model(input_ids=tokens['input_ids'], attention_mask=tokens['attention_mask'])\n        probabilities = torch.softmax(outputs.logits, dim=-1)\n\n    return probabilities.tolist()\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser(description=\"Инференс с медицинской нейросетью\")\n    parser.add_argument(\"--model\", required=True, help=\"Путь к сохраненной модели\")\n    parser.add_argument(\"--text\", required=True, help=\"Текст для анализа\")\n    args = parser.parse_args()\n\n    model, tokenizer = load_model_and_tokenizer(args.model)\n    result = infer_model(model, tokenizer, args.text)\n    logger.info(f\"Результаты предсказания: {result}\")\n```",
    "lines_of_code": 35
  },
  {
    "file": "prepare_data.py",
    "timestamp": "2025-11-14T03:44:49.031815",
    "metrics": {
      "complexity": "prepare_data.py\n    F 13:0 prepare_data - A (3)\n",
      "maintainability": "prepare_data.py - A (84.99)\n"
    },
    "ai_recommendations": "В целом, код написан хорошо и следует большинству best practices. Однако есть несколько мест, которые можно улучшить:\n\n1. **Обработка исключений**: В коде отсутствует обработка исключений при чтении CSV-файла. Если файл не найден или поврежден, программа просто завершится с ошибкой. Лучше добавить блок try/except, чтобы обработать эти ситуации и вывести понятное сообщение об ошибке.\n\n2. **Логирование**: Вместо использования глобального логгера `logger = logging.getLogger(__name__)`, можно использовать локальный логгер внутри функции. Это улучшит читаемость кода и сделает его более модульным.\n\n3. **Документация**: Документация функции `prepare_data` хороша, но можно добавить больше деталей о том, что делает функция, какие аргументы она принимает и что она возвращает.\n\n4. **Читаемость кода**: Вместо использования `os.path.join(output_dir, \"train.csv\")` и `os.path.join(output_dir, \"test.csv\")` можно создать переменные `train_file_path` и `test_file_path` для улучшения читаемости кода.\n\n5. **Параметр `test_size`**: Параметр `test_size` в функции `prepare_data` по умолчанию равен 0.2. Это значение можно сделать настраиваемым, добавив его в аргументы командной строки.\n\n6. **Оптимизация**: Вместо использования `data[\"text\"].str.strip()` для очистки данных, можно использовать `data[\"text\"] = data[\"text\"].apply(lambda x: x.strip())`. Это может быть быстрее на больших наборах данных.\n\n7. **Безопасность**: В коде нет явных проблем с безопасностью. Однако, всегда стоит быть осторожным при работе с внешними файлами и убедиться, что они не содержат вредоносного кода или недопустимых данных.",
    "lines_of_code": 53
  },
  {
    "file": "scripts/fix_csv_headers.py",
    "timestamp": "2025-11-14T03:45:03.696144",
    "metrics": {
      "complexity": "",
      "maintainability": "scripts/fix_csv_headers.py - A (90.78)\n"
    },
    "ai_recommendations": "В целом, код написан хорошо, но есть несколько моментов, которые можно улучшить:\n\n1. Производительность: Вместо того, чтобы сначала считывать все строки из файла в память, а затем фильтровать их, можно считывать и фильтровать строки по одной. Это позволит снизить потребление памяти, особенно при работе с большими файлами.\n\n2. Безопасность: В данном случае, код открывает файл для записи после чтения, что может привести к потере данных, если произойдет ошибка во время обработки. Лучше использовать временный файл для записи, а затем переименовать его в оригинальный файл после успешного завершения обработки.\n\n3. Читаемость: Цикл for можно заменить на более понятный и компактный list comprehension.\n\n4. Best practices: Лучше использовать модуль logging для вывода сообщений, а не print. Это позволит более гибко управлять выводом сообщений, включая уровень детализации, форматирование и перенаправление в файл или другие места.\n\nВот пример улучшенного кода:\n\n```python\n#!/usr/bin/env python3\n\"\"\"Fix CSV file by removing invalid header rows\"\"\"\n\nimport csv\nimport sys\nimport logging\nimport tempfile\nimport shutil\n\nlogging.basicConfig(level=logging.INFO)\n\n# Temporary file for cleaned CSV\ntemp_file = tempfile.NamedTemporaryFile(delete=False)\n\nwith open(\"training-data/medical_training_data.csv\", \"r\", encoding=\"utf-8\") as f_in, open(temp_file.name, \"w\", encoding=\"utf-8\") as f_out:\n    valid_lines = 0\n    invalid_lines = 0\n    for i, line in enumerate(f_in):\n        if i == 0 or \",\" in line:  # Keep the header row and lines with CSV data\n            f_out.write(line)\n            valid_lines += 1\n        else:\n            logging.info(f\"Removing invalid line {i+1}: {line.strip()}\")\n            invalid_lines += 1\n\n# Replace the original file with the cleaned one\nshutil.move(temp_file.name, \"training-data/medical_training_data.csv\")\n\nlogging.info(f\"\\nDone! Kept {valid_lines} valid lines, removed {invalid_lines} invalid lines\")\n```\n\nЭтот код делает то же самое, что и оригинальный, но более эффективно и безопасно.",
    "lines_of_code": 29
  }
]