[
  {
    "file": "train.py",
    "timestamp": "2025-11-16T03:46:45.195056",
    "metrics": {
      "complexity": "train.py\n    F 77:0 train_model - A (4)\n    F 47:0 prepare_data - A (3)\n    C 22:0 MedicalDataset - A (2)\n    M 23:4 MedicalDataset.__init__ - A (1)\n    M 28:4 MedicalDataset.__len__ - A (1)\n    M 31:4 MedicalDataset.__getitem__ - A (1)\n",
      "maintainability": "train.py - A (69.54)\n"
    },
    "ai_recommendations": "В целом, код хорошо структурирован и легко читается. Однако есть несколько моментов, которые можно улучшить:\n\n1. **Обработка ошибок и исключений**: В коде есть проверка на наличие необходимых столбцов в CSV-файле, но нет проверки на существование самого файла. Это может привести к неинформативным ошибкам, если файл не найден. Рекомендуется добавить обработку исключений для чтения файла.\n\n2. **Оптимизация использования памяти**: В текущем коде весь CSV-файл загружается в память сразу. Если файл очень большой, это может привести к проблемам с памятью. Рекомендуется использовать chunksize в pd.read_csv для чтения файла по частям.\n\n3. **Параметры обучения**: В коде захардкожены параметры обучения, такие как количество эпох, размер батча и скорость обучения. Хорошей практикой является вынесение этих параметров в аргументы командной строки или конфигурационный файл, чтобы можно было легко менять их без изменения кода.\n\n4. **Оптимизация производительности**: В цикле обучения после каждого батча вызывается `optimizer.zero_grad()`. Это необходимо для очистки градиентов перед следующим батчем, но это может быть неэффективно, если ваши батчи очень маленькие. Вместо этого можно вызывать `optimizer.zero_grad(set_to_none=True)`, что будет более эффективно с точки зрения использования памяти.\n\n5. **Сохранение прогресса обучения**: В текущем коде после каждой эпохи сохраняется только потеря. Хорошей практикой является сохранение не только потерь, но и других метрик, таких как точность, а также сохранение модели после каждой эпохи. Это позволит вам восстановить обучение с последней эпохи, если что-то пойдет не так.\n\n6. **Комментарии и документация**: Код хорошо документирован, но некоторые функции и классы не имеют комментариев или строк документации. Хорошей практикой является добавление строк документации ко всем публичным классам и функциям, описывающих их назначение, параметры и возвращаемые значения.",
    "lines_of_code": 124
  },
  {
    "file": "main.py",
    "timestamp": "2025-11-16T03:47:01.260889",
    "metrics": {
      "complexity": "main.py\n    F 32:0 train_model - A (4)\n    F 72:0 predict - A (2)\n    C 14:0 MedicalNet - A (2)\n    F 92:0 main - A (1)\n    M 15:4 MedicalNet.__init__ - A (1)\n    M 22:4 MedicalNet.forward - A (1)\n",
      "maintainability": "main.py - A (74.92)\n"
    },
    "ai_recommendations": "В целом, ваш код хорошо структурирован и легко читается. Однако, есть несколько мест, где можно внести улучшения.\n\n1. **Импорты**: В начале файла импортируется модуль `os`, который не используется в коде. Лишние импорты следует удалять, чтобы не замедлять загрузку скрипта и не занимать лишнюю память.\n\n2. **Архитектура модели**: Ваша модель `MedicalNet` использует три полносвязных слоя (`nn.Linear`). Это может быть избыточно для некоторых задач, и возможно, стоит рассмотреть упрощение архитектуры. Также, вы используете dropout после второго слоя, что может помочь в борьбе с переобучением, но может замедлить сходимость обучения. Возможно, стоит рассмотреть использование dropout только во время обучения, а не во время инференса.\n\n3. **Обучение модели**: Ваша функция `train_model` выполняет обучение и сохранение модели. Это может быть неудобно, если вы хотите обучить модель, но не сохранять ее. Рекомендуется разделить эти две операции на разные функции.\n\n4. **Прогнозирование**: Ваша функция `predict` загружает модель каждый раз, когда она вызывается. Это может быть неэффективно, если вы делаете много прогнозов. Вместо этого, рекомендуется загружать модель один раз, а затем использовать ее для всех прогнозов.\n\n5. **Обработка ошибок**: Ваш код не содержит обработки ошибок. Например, что произойдет, если файл модели не найден? Что произойдет, если входные данные имеют неправильный формат? Рекомендуется добавить обработку ошибок, чтобы ваш код был более надежным.\n\n6. **Логирование**: Ваш код использует `print` для вывода информации. Это может быть неудобно, если вы хотите сохранить эту информацию в файл или отправить ее в систему логирования. Рекомендуется использовать модуль `logging` вместо `print`.\n\n7. **Тестирование**: Ваш код не содержит тестов. Тесты помогают убедиться, что ваш код работает правильно, и облегчают обнаружение ошибок. Рекомендуется добавить тесты для ваших функций.",
    "lines_of_code": 111
  },
  {
    "file": "infer.py",
    "timestamp": "2025-11-16T03:47:21.135943",
    "metrics": {
      "complexity": "infer.py\n    F 10:0 infer_model - A (2)\n",
      "maintainability": "infer.py - A (74.30)\n"
    },
    "ai_recommendations": "В целом, код хорошо написан и легко читается. Однако, есть несколько моментов, которые можно улучшить:\n\n1. **Производительность**: Модель и токенизатор загружаются при каждом вызове функции `infer_model`. Если вы планируете вызывать эту функцию несколько раз, это может привести к значительным затратам времени. Рекомендуется загрузить модель и токенизатор один раз и затем использовать их несколько раз.\n\n2. **Читаемость**: В коде отсутствуют комментарии, которые могли бы помочь другим разработчикам быстрее понять, что делает код. Хотя большая часть кода довольно прямолинейна, добавление комментариев к ключевым частям кода может быть полезным.\n\n3. **Best practices**: Вместо использования глобальной переменной `DEVICE`, можно передать ее как аргумент функции `infer_model`. Это делает функцию более универсальной и уменьшает зависимость от глобального состояния.\n\n4. **Безопасность**: В данном случае, особенных проблем с безопасностью не наблюдается. Однако, всегда стоит быть аккуратным при работе с внешними данными, такими как аргументы командной строки.\n\nИтоговый код может выглядеть так:\n\n```python\nimport argparse\nimport torch\nfrom transformers import AutoModelForSequenceClassification, AutoTokenizer\n\ndef load_model_and_tokenizer(model_dir, device):\n    \"\"\"Загрузка модели и токенизатора.\"\"\"\n    tokenizer = AutoTokenizer.from_pretrained(model_dir)\n    model = AutoModelForSequenceClassification.from_pretrained(model_dir)\n    model.to(device)\n    return model, tokenizer\n\ndef infer_model(model, tokenizer, device, text):\n    \"\"\"Инференс модели.\"\"\"\n    tokens = tokenizer(\n        text, return_tensors=\"pt\", truncation=True, padding=True, max_length=128\n    )\n    tokens = {k: v.to(device) for k, v in tokens.items()}\n\n    model.eval()\n    with torch.no_grad():\n        outputs = model(**tokens)\n        probabilities = torch.softmax(outputs.logits, dim=-1)\n\n    return probabilities.tolist()\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser(description=\"Инференс с медицинской нейросетью\")\n    parser.add_argument(\"--model\", required=True, help=\"Путь к сохраненной модели\")\n    parser.add_argument(\"--text\", required=True, help=\"Текст для анализа\")\n    args = parser.parse_args()\n\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model, tokenizer = load_model_and_tokenizer(args.model, device)\n    result = infer_model(model, tokenizer, device, args.text)\n\n    print(f\"Результаты предсказания: {result}\")\n```\n",
    "lines_of_code": 35
  },
  {
    "file": "prepare_data.py",
    "timestamp": "2025-11-16T03:47:44.605663",
    "metrics": {
      "complexity": "prepare_data.py\n    F 13:0 prepare_data - A (3)\n",
      "maintainability": "prepare_data.py - A (84.99)\n"
    },
    "ai_recommendations": "В целом, код хорошо структурирован, легко читаем и следует стандартам Python. Однако есть несколько моментов, которые можно улучшить:\n\n1. **Обработка исключений**: В коде отсутствует обработка исключений при чтении CSV-файла. Если файл не существует или имеет неправильный формат, программа просто выдаст ошибку и завершится. Это может быть неприятно для пользователя. Лучше добавить блок try/except для обработки таких ситуаций.\n\n2. **Валидация входных данных**: Проверка наличия столбцов 'text' и 'label' в данных - это хорошо, но что если эти столбцы пустые? Возможно, стоит добавить проверку на наличие значений в этих столбцах.\n\n3. **Логирование**: В коде используется логирование, что является хорошей практикой. Однако, можно добавить больше информации в логи, например, время выполнения каждого этапа обработки данных.\n\n4. **Документация**: Функция `prepare_data` хорошо документирована, но для полноты картины стоит добавить документацию и к основной части кода, которая запускается при выполнении скрипта.\n\n5. **Тестирование**: В коде нет тестов. Хотя это не всегда необходимо для небольших скриптов, добавление базовых тестов может помочь обнаружить ошибки и упростить будущую поддержку кода.\n\n6. **Оптимизация**: В данном случае, оптимизация может быть не критична, но если размер данных велик, то можно использовать параметр `low_memory=False` при чтении CSV файла для улучшения производительности. \n\n7. **Best Practices**: В коде используются глобальные переменные для аргументов командной строки. Лучше передавать эти значения напрямую в функцию `prepare_data`, чтобы сделать код более модульным и упростить тестирование.",
    "lines_of_code": 53
  },
  {
    "file": "scripts/fix_csv_headers.py",
    "timestamp": "2025-11-16T03:48:02.585149",
    "metrics": {
      "complexity": "",
      "maintainability": "scripts/fix_csv_headers.py - A (90.78)\n"
    },
    "ai_recommendations": "1. Производительность: Вместо того, чтобы сначала читать все строки из файла в память, а затем проходить по ним, вы можете сразу же фильтровать строки при чтении. Это улучшит производительность, особенно для больших файлов.\n\n2. Безопасность: Ваш код открывает файл для записи, что может привести к потере данных, если произойдет ошибка во время обработки. Лучше сначала записать данные во временный файл, а затем переименовать его в исходный файл.\n\n3. Читаемость: Ваш код в целом хорошо структурирован и легко читается. Однако, вы можете улучшить читаемость, убрав комментарии, которые просто повторяют то, что делает код. Например, комментарий \"# Read the CSV file\" не несет дополнительной информации.\n\n4. Best practices: Вместо того, чтобы использовать `readlines()` и `writelines()`, вы можете использовать модуль `csv` для чтения и записи CSV-файлов. Это упростит код и сделает его более надежным.\n\nВот улучшенная версия вашего кода:\n\n```python\n#!/usr/bin/env python3\n\"\"\"Fix CSV file by removing invalid header rows\"\"\"\n\nimport csv\nimport os\nimport tempfile\n\n# Open the CSV file\nwith open(\"training-data/medical_training_data.csv\", \"r\", encoding=\"utf-8\") as f, \\\n     tempfile.NamedTemporaryFile(mode=\"w\", delete=False) as tmp_file:\n\n    reader = csv.reader(f)\n    writer = csv.writer(tmp_file)\n\n    valid_lines = 0\n    invalid_lines = 0\n\n    for i, row in enumerate(reader):\n        if i == 0 or len(row) > 1:  # Keep the header row and rows with CSV data\n            writer.writerow(row)\n            valid_lines += 1\n        else:\n            print(f\"Removing invalid line {i+1}: {','.join(row)}\")\n            invalid_lines += 1\n\nos.rename(tmp_file.name, \"training-data/medical_training_data.csv\")\n\nprint(\n    f\"\\nDone! Kept {valid_lines} valid lines, removed {invalid_lines} invalid lines\"\n)\n```\n\nЭтот код использует модуль `csv` для чтения и записи CSV-файлов, что делает его более надежным. Он также записывает данные во временный файл, чтобы предотвратить потерю данных в случае ошибки. Кроме того, он сразу же фильтрует строки при чтении, что улучшает производительность.",
    "lines_of_code": 29
  }
]