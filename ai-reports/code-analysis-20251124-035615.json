[
  {
    "file": "train.py",
    "timestamp": "2025-11-24T03:54:58.427790",
    "metrics": {
      "complexity": "train.py\n    F 77:0 train_model - A (4)\n    F 47:0 prepare_data - A (3)\n    C 22:0 MedicalDataset - A (2)\n    M 23:4 MedicalDataset.__init__ - A (1)\n    M 28:4 MedicalDataset.__len__ - A (1)\n    M 31:4 MedicalDataset.__getitem__ - A (1)\n",
      "maintainability": "train.py - A (69.54)\n"
    },
    "ai_recommendations": "В целом, код хорошо структурирован и читаем. Однако, есть несколько мест, где можно внести улучшения.\n\n1. **Обработка ошибок**: В функции `prepare_data`, при чтении CSV-файла, может возникнуть ошибка, если файл не существует или недоступен. Это можно обработать с помощью блока try/except.\n\n2. **Читаемость**: В функции `train_model`, цикл обучения может быть сложным для понимания для новых разработчиков. Рекомендуется добавить комментарии для улучшения читаемости.\n\n3. **Производительность**: В функции `train_model`, вы используете `model.train()` вне цикла эпох. Это означает, что модель будет переключаться в режим обучения только один раз. Если в вашем коде где-то есть `model.eval()`, то модель не будет переключаться обратно в режим обучения при следующей эпохе. Рекомендуется переместить `model.train()` внутрь цикла эпох.\n\n4. **Best Practices**: Вместо использования `torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")` напрямую в глобальном пространстве, рекомендуется использовать функцию для определения устройства. Это позволит легко изменять устройство в одном месте, если потребуется.\n\n5. **Best Practices**: Вместо использования констант в коде, таких как `epochs=3, batch_size=16, learning_rate=2e-5`, рекомендуется использовать аргументы командной строки или конфигурационный файл. Это делает код более гибким и позволяет легко изменять параметры без необходимости изменения кода.\n\n6. **Best Practices**: Вместо сохранения модели и токенизатора в одном и том же каталоге, рекомендуется сохранять их в разных подкаталогах. Это облегчает управление файлами и предотвращает возможные конфликты имен файлов.\n\n7. **Безопасность**: При работе с файлами и директориями рекомендуется использовать функции из модуля `pathlib` вместо `os.path`. Модуль `pathlib` более безопасен и удобен для работы с путями к файлам и директориям.",
    "lines_of_code": 124
  },
  {
    "file": "main.py",
    "timestamp": "2025-11-24T03:55:16.527289",
    "metrics": {
      "complexity": "main.py\n    F 32:0 train_model - A (4)\n    F 72:0 predict - A (2)\n    C 14:0 MedicalNet - A (2)\n    F 92:0 main - A (1)\n    M 15:4 MedicalNet.__init__ - A (1)\n    M 22:4 MedicalNet.forward - A (1)\n",
      "maintainability": "main.py - A (74.92)\n"
    },
    "ai_recommendations": "В целом, код хорошо структурирован и легко читаем. Однако, есть несколько моментов, которые можно улучшить:\n\n1. **Импорты**: В начале файла импортируется модуль `os`, который не используется в коде. Неиспользуемые импорты следует удалять, чтобы улучшить читаемость и производительность кода.\n\n2. **Документация**: Ваш код будет легче понять и поддерживать, если вы добавите комментарии и строковые документы (docstrings) к функциям и классам. Это особенно важно для функций `train_model` и `predict`, которые выполняют сложные операции.\n\n3. **Обработка ошибок**: Ваш код не обрабатывает ошибки, которые могут возникнуть при загрузке модели в функции `predict`. Чтобы улучшить надежность кода, добавьте обработку исключений, например, с помощью блоков `try/except`.\n\n4. **Параметры обучения**: Ваш код всегда использует один и тот же коэффициент обучения и количество эпох. Это может быть неоптимально для разных наборов данных. Рассмотрите возможность передачи этих параметров в функцию `train_model` в качестве аргументов.\n\n5. **Жесткая привязка к устройству**: Ваш код автоматически выбирает CUDA, если он доступен, и в противном случае использует CPU. Это может быть неоптимально, если вы хотите иметь возможность выбирать устройство. Рассмотрите возможность передачи устройства в качестве аргумента функциям `train_model` и `predict`.\n\n6. **Сохранение модели**: Ваш код сохраняет модель в файл с жестко заданным именем. Это может быть неудобно, если вы хотите обучить и сохранить несколько моделей. Рассмотрите возможность передачи имени файла в качестве аргумента функции `train_model`.\n\n7. **Улучшение читаемости**: Ваш код будет легче читать, если вы разделите его на несколько меньших функций. Например, вы можете вынести инициализацию модели и оптимизатора в отдельную функцию.\n\n8. **Best practices**: Вместо использования `torch.tensor(data, dtype=torch.float32)` для преобразования данных, рекомендуется использовать `data.float()`. Это более эффективно и улучшает читаемость кода.",
    "lines_of_code": 111
  },
  {
    "file": "infer.py",
    "timestamp": "2025-11-24T03:55:39.311464",
    "metrics": {
      "complexity": "infer.py\n    F 10:0 infer_model - A (2)\n",
      "maintainability": "infer.py - A (74.30)\n"
    },
    "ai_recommendations": "В целом, код хорошо структурирован и читаем. Однако есть несколько мест, которые можно улучшить:\n\n1. **Инициализация модели и токенизатора:** В текущем коде, каждый раз при вызове функции `infer_model`, модель и токенизатор загружаются заново. Это может быть очень неэффективно, если вы делаете предсказания многократно. Лучше инициализировать модель и токенизатор один раз, а затем использовать их для всех предсказаний. \n\n2. **Обработка ошибок:** В текущем коде нет обработки ошибок. Например, что произойдет, если указанный путь к модели неверен? Лучше добавить обработку ошибок для таких ситуаций.\n\n3. **Комментарии и документация:** Хотя код в целом читаем, некоторые части могут быть непонятны для людей, не знакомых с библиотеками `transformers` и `torch`. Лучше добавить комментарии, объясняющие, что делает каждая часть кода.\n\n4. **Константы:** Вместо использования константы `max_length=128` в коде, лучше вынести её в глобальную переменную, чтобы легко можно было изменить её при необходимости.\n\n5. **Безопасность:** В данном коде нет явных проблем с безопасностью, но всегда стоит быть внимательным при работе с внешними данными, такими как аргументы командной строки.\n\nВот пример улучшенного кода:\n\n```python\nimport argparse\n\nimport torch\nfrom transformers import AutoModelForSequenceClassification, AutoTokenizer\n\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nMAX_LENGTH = 128\n\n# Инициализация модели и токенизатора\ntokenizer = None\nmodel = None\n\ndef load_model_and_tokenizer(model_dir):\n    global tokenizer, model\n    try:\n        tokenizer = AutoTokenizer.from_pretrained(model_dir)\n        model = AutoModelForSequenceClassification.from_pretrained(model_dir)\n        model.to(DEVICE)\n    except Exception as e:\n        print(f\"Ошибка при загрузке модели: {e}\")\n        exit(1)\n\ndef infer_model(text):\n    tokens = tokenizer(\n        text, return_tensors=\"pt\", truncation=True, padding=True, max_length=MAX_LENGTH\n    )\n    tokens = {k: v.to(DEVICE) for k, v in tokens.items()}\n\n    model.eval()\n    with torch.no_grad():\n        outputs = model(**tokens)\n        probabilities = torch.softmax(outputs.logits, dim=-1)\n\n    return probabilities.tolist()\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser(description=\"Инференс с медицинской нейросетью\")\n    parser.add_argument(\"--model\", required=True, help=\"Путь к сохраненной модели\")\n    parser.add_argument(\"--text\", required=True, help=\"Текст для анализа\")\n    args = parser.parse_args()\n\n    load_model_and_tokenizer(args.model)\n    result = infer_model(args.text)\n    print(f\"Результаты предсказания: {result}\")\n```\n\nТакой код будет более эффективным, безопасным и читаемым.",
    "lines_of_code": 35
  },
  {
    "file": "prepare_data.py",
    "timestamp": "2025-11-24T03:55:57.242798",
    "metrics": {
      "complexity": "prepare_data.py\n    F 13:0 prepare_data - A (3)\n",
      "maintainability": "prepare_data.py - A (84.99)\n"
    },
    "ai_recommendations": "В целом, код хорошо структурирован, читаем и следует ряду best practices. Однако, есть несколько моментов, которые можно улучшить:\n\n1. **Обработка исключений**: В коде отсутствует обработка исключений при чтении CSV-файла. Если файл не существует или поврежден, программа завершится с ошибкой. Хорошей практикой было бы добавить блок try/except для обработки возможных ошибок при чтении файла.\n\n2. **Валидация данных**: После чтения данных из CSV-файла, код проверяет наличие столбцов 'text' и 'label'. Это хорошо, но можно добавить дополнительную валидацию данных, например, проверить, не содержат ли столбцы 'text' и 'label' пустые значения.\n\n3. **Оптимизация использования памяти**: В зависимости от размера входного файла, чтение всего файла в память с помощью `pd.read_csv()` может быть неэффективным. Если файл очень большой, это может привести к нехватке памяти. Возможное решение - использовать параметр `chunksize` в `pd.read_csv()`, чтобы читать файл по частям.\n\n4. **Документация**: Код хорошо документирован, но можно добавить больше информации в строку документации функции `prepare_data()`, например, описание формата входного файла и ожидаемого результата.\n\n5. **Тестирование**: В коде отсутствуют тесты. Хорошей практикой было бы добавить модульные тесты для функции `prepare_data()`, чтобы убедиться, что она работает правильно.\n\n6. **Константы**: В коде используется константа `random_state=42` для функции `train_test_split()`. Хотя это общепринятая практика, было бы хорошо вынести эту константу в глобальную переменную в верхней части файла, чтобы ее можно было легко изменить при необходимости.",
    "lines_of_code": 53
  },
  {
    "file": "scripts/fix_csv_headers.py",
    "timestamp": "2025-11-24T03:56:15.968164",
    "metrics": {
      "complexity": "",
      "maintainability": "scripts/fix_csv_headers.py - A (90.78)\n"
    },
    "ai_recommendations": "В целом, код написан хорошо и достаточно читаем, но есть несколько моментов, которые можно улучшить:\n\n1. **Производительность**: Вместо того, чтобы сначала считывать все строки в память, а затем фильтровать их, можно сделать это одновременно. Это позволит сэкономить память, особенно при работе с большими файлами.\n\n2. **Безопасность**: В данном случае код открывает, изменяет и снова сохраняет файл. Если в процессе что-то пойдет не так, исходный файл может быть поврежден. Лучше сохранять результат в новый файл.\n\n3. **Читаемость и best practices**: Вместо использования индекса для определения заголовка, можно использовать флаг, который будет более понятным. Также можно использовать csv.reader для чтения CSV-файла, это более надежный и универсальный подход.\n\nВот улучшенная версия кода:\n\n```python\n#!/usr/bin/env python3\n\"\"\"Fix CSV file by removing invalid header rows\"\"\"\n\nimport csv\nimport sys\n\ninput_file = \"training-data/medical_training_data.csv\"\noutput_file = \"training-data/cleaned_medical_training_data.csv\"\n\n# Open the input and output files\nwith open(input_file, \"r\", encoding=\"utf-8\") as input_f, \\\n     open(output_file, \"w\", encoding=\"utf-8\") as output_f:\n\n    # Use csv reader and writer\n    reader = csv.reader(input_f)\n    writer = csv.writer(output_f)\n\n    valid_lines = 0\n    invalid_lines = 0\n\n    # Process each line\n    for i, row in enumerate(reader):\n        # Keep the header row or rows with CSV data\n        if i == 0 or len(row) > 1:\n            writer.writerow(row)\n            valid_lines += 1\n        else:\n            print(f\"Removing invalid line {i+1}: {', '.join(row)}\")\n            invalid_lines += 1\n\nprint(\n    f\"\\nDone! Kept {valid_lines} valid lines, removed {invalid_lines} invalid lines\"\n)\n```\n\nВ этой версии кода мы используем csv.reader и csv.writer для работы с CSV-файлами, что делает код более надежным и универсальным. Мы также сразу записываем валидные строки в выходной файл, что позволяет сэкономить память.",
    "lines_of_code": 29
  }
]