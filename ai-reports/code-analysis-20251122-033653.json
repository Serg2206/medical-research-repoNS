[
  {
    "file": "train.py",
    "timestamp": "2025-11-22T03:35:37.980739",
    "metrics": {
      "complexity": "train.py\n    F 77:0 train_model - A (4)\n    F 47:0 prepare_data - A (3)\n    C 22:0 MedicalDataset - A (2)\n    M 23:4 MedicalDataset.__init__ - A (1)\n    M 28:4 MedicalDataset.__len__ - A (1)\n    M 31:4 MedicalDataset.__getitem__ - A (1)\n",
      "maintainability": "train.py - A (69.54)\n"
    },
    "ai_recommendations": "В целом, код хорошо структурирован и читаем, но есть несколько моментов, которые можно улучшить:\n\n1. **Обработка ошибок и исключений**: В функции `prepare_data` есть проверка на наличие необходимых столбцов в данных, но в остальной части кода отсутствует обработка исключений. Например, при чтении CSV-файла, инициализации модели, сохранении модели и т.д. могут возникнуть ошибки. Хорошей практикой является оборачивание таких блоков кода в `try/except` для обработки возможных ошибок.\n\n2. **Производительность**: В функции `train_model` используется цикл для обучения модели. Это может быть неэффективно, если датасет большой. Вместо этого можно использовать библиотеки, такие как PyTorch Lightning, которые обеспечивают более эффективное обучение и упрощают код.\n\n3. **Читаемость**: В функции `__getitem__` в классе `MedicalDataset` создается словарь `tokens`, а затем из него извлекаются значения. Это может быть немного запутанно. Вместо этого можно сразу возвращать кортеж значений.\n\n4. **Best Practices**: Вместо использования глобальных переменных `MODEL_NAME` и `DEVICE` можно передавать их как аргументы в функции. Это улучшит модульность кода и позволит легче переиспользовать функции.\n\n5. **Тестирование**: В коде отсутствуют тесты. Хорошей практикой является написание unit-тестов для проверки корректности работы функций и методов.\n\n6. **Документация**: Хотя некоторые функции имеют docstrings, некоторые из них (например, `train_model`) не имеют. Хорошей практикой является предоставление docstrings для всех функций и методов, описывающих их назначение, аргументы и возвращаемые значения.\n\n7. **Безопасность**: В данном коде нет явных проблем с безопасностью, но всегда стоит убедиться, что используемые библиотеки и зависимости обновлены до последних версий, чтобы избежать возможных уязвимостей.",
    "lines_of_code": 124
  },
  {
    "file": "main.py",
    "timestamp": "2025-11-22T03:35:54.359330",
    "metrics": {
      "complexity": "main.py\n    F 32:0 train_model - A (4)\n    F 72:0 predict - A (2)\n    C 14:0 MedicalNet - A (2)\n    F 92:0 main - A (1)\n    M 15:4 MedicalNet.__init__ - A (1)\n    M 22:4 MedicalNet.forward - A (1)\n",
      "maintainability": "main.py - A (74.92)\n"
    },
    "ai_recommendations": "В целом, код хорошо структурирован и легко читаем. Однако есть несколько моментов, которые можно улучшить:\n\n1. **Импорты**: В начале файла импортируется модуль `os`, который в дальнейшем не используется. Это может ввести в заблуждение других разработчиков, которые будут читать ваш код. Лучше убрать этот импорт.\n\n2. **Комментарии**: Хотя комментарии полезны, некоторые из них избыточны и могут быть удалены. Например, комментарий `# Определение архитектуры модели` перед определением класса `MedicalNet` не добавляет дополнительной информации, так как само название класса уже говорит о том, что это модель.\n\n3. **Обработка ошибок**: В функции `predict` вы загружаете веса модели из файла, но не обрабатываете исключение, которое может возникнуть, если файла не существует. Лучше добавить блок `try/except` для обработки таких ситуаций.\n\n4. **Магические числа**: В коде есть несколько \"магических чисел\" (например, `epochs=20`, `batch_size=32`, `lr=0.001`). Лучше вынести эти значения в константы в начале файла или сделать их параметрами функций/методов, чтобы упростить изменение этих значений в будущем.\n\n5. **Печать прогресса обучения**: Вместо того чтобы печатать потери после каждой эпохи, можно использовать инструменты вроде `tqdm` для отображения прогресса обучения в более удобном формате.\n\n6. **Сохранение и загрузка модели**: Вместо сохранения только весов модели, можно сохранять всю модель, включая ее структуру. Это позволит загружать модель в одну строку кода и избавит от необходимости указывать структуру модели при загрузке.\n\n7. **Проверка на CUDA**: Проверка на доступность CUDA выполняется несколько раз. Лучше выполнить эту проверку один раз и сохранить результат в переменную, которую затем можно использовать во всем коде.\n\n8. **Типы данных**: В функциях `train_model` и `predict` вы преобразуете данные в тензоры и задаете тип данных. Это повторяющийся код, который можно вынести в отдельную функцию.",
    "lines_of_code": 111
  },
  {
    "file": "infer.py",
    "timestamp": "2025-11-22T03:36:27.768853",
    "metrics": {
      "complexity": "infer.py\n    F 10:0 infer_model - A (2)\n",
      "maintainability": "infer.py - A (74.30)\n"
    },
    "ai_recommendations": "В целом, код выглядит хорошо структурированным и читаемым. Однако есть несколько моментов, которые можно улучшить:\n\n1. **Производительность**: Инициализация токенизатора и модели происходит каждый раз при вызове функции `infer_model`. Если вы планируете вызывать эту функцию несколько раз, это может негативно сказаться на производительности. Рекомендуется инициализировать токенизатор и модель один раз, а затем передавать их в функцию как аргументы.\n\n2. **Читаемость**: Добавьте комментарии к функциям и основным блокам кода. Это поможет другим разработчикам быстрее понять, что делает ваш код.\n\n3. **Best Practices**: Вместо использования глобальной переменной `DEVICE`, рассмотрите возможность передачи ее в качестве аргумента функции. Это делает функцию более гибкой и позволяет легче контролировать, на каком устройстве выполняется код.\n\n4. **Безопасность**: Ваш код не содержит явных проблем безопасности. Однако стоит учесть, что если входные данные не проверяются на валидность, это может привести к ошибкам. В вашем случае, вы можете добавить проверку на то, что входной текст является строкой и не пустой.\n\nВот как может выглядеть улучшенный код:\n\n```python\nimport argparse\nimport torch\nfrom transformers import AutoModelForSequenceClassification, AutoTokenizer\n\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\ndef init_model(model_dir):\n    tokenizer = AutoTokenizer.from_pretrained(model_dir)\n    model = AutoModelForSequenceClassification.from_pretrained(model_dir)\n    model.to(DEVICE)\n    return tokenizer, model\n\ndef infer_model(tokenizer, model, text):\n    assert isinstance(text, str), \"Input text should be a string\"\n    assert text, \"Input text should not be empty\"\n\n    tokens = tokenizer(\n        text, return_tensors=\"pt\", truncation=True, padding=True, max_length=128\n    )\n    tokens = {k: v.to(DEVICE) for k, v in tokens.items()}\n\n    model.eval()\n    with torch.no_grad():\n        outputs = model(**tokens)\n        probabilities = torch.softmax(outputs.logits, dim=-1)\n\n    return probabilities.tolist()\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser(description=\"Инференс с медицинской нейросетью\")\n    parser.add_argument(\"--model\", required=True, help=\"Путь к сохраненной модели\")\n    parser.add_argument(\"--text\", required=True, help=\"Текст для анализа\")\n    args = parser.parse_args()\n\n    tokenizer, model = init_model(args.model)\n    result = infer_model(tokenizer, model, args.text)\n    print(f\"Результаты предсказания: {result}\")\n```\n",
    "lines_of_code": 35
  },
  {
    "file": "prepare_data.py",
    "timestamp": "2025-11-22T03:36:41.957065",
    "metrics": {
      "complexity": "prepare_data.py\n    F 13:0 prepare_data - A (3)\n",
      "maintainability": "prepare_data.py - A (84.99)\n"
    },
    "ai_recommendations": "В целом, код хорошо структурирован, читаем и следует многим best practices. Однако есть несколько областей, которые можно улучшить:\n\n1. **Обработка исключений**: Ваш код может вызвать исключение, если CSV-файл не содержит столбцов 'text' и 'label'. Это хорошо, но было бы еще лучше, если бы вы обрабатывали это исключение на более высоком уровне, чтобы предотвратить аварийное завершение всего процесса.\n\n2. **Документация**: Ваш код хорошо документирован, но вы могли бы добавить больше информации о том, что делает ваша функция `prepare_data`. Например, вы могли бы указать, что она также очищает данные и сохраняет их в указанной директории.\n\n3. **Тестирование**: Ваш код не содержит тестов. Хорошей практикой является написание модульных тестов для проверки корректности работы вашего кода.\n\n4. **Читаемость**: Ваш код в целом хорошо структурирован и читаем, но вы могли бы улучшить читаемость, избегая магических чисел, таких как `42` в `train_test_split`. Вместо этого вы могли бы определить это число как константу в начале файла с понятным именем.\n\n5. **Производительность**: Ваш код может быть неэффективным, если входной CSV-файл очень большой, поскольку вы загружаете весь файл в память с помощью `pd.read_csv`. Вместо этого вы могли бы использовать итераторы pandas для чтения и обработки файла по частям.\n\n6. **Безопасность**: Ваш код в целом безопасен, но вы могли бы добавить проверку на существование входного файла перед его чтением, чтобы избежать возможных ошибок ввода-вывода.",
    "lines_of_code": 53
  },
  {
    "file": "scripts/fix_csv_headers.py",
    "timestamp": "2025-11-22T03:36:53.408857",
    "metrics": {
      "complexity": "",
      "maintainability": "scripts/fix_csv_headers.py - A (90.78)\n"
    },
    "ai_recommendations": "В целом, код читаем и понятен. Однако есть несколько моментов, которые можно улучшить:\n\n1. **Производительность**: Вместо того, чтобы сначала считывать все строки из файла, а затем фильтровать их, можно считывать и фильтровать строки по одной. Это позволит снизить потребление памяти, особенно при работе с большими файлами.\n\n2. **Безопасность**: Скрипт перезаписывает исходный файл, что может привести к потере данных. Лучше сохранять очищенные данные в новый файл.\n\n3. **Читаемость и best practices**: Код можно сделать более читаемым и Pythonic, используя list comprehension для фильтрации строк. Также можно использовать модуль `csv` для чтения и записи CSV-файлов, что упростит код и сделает его более надежным.\n\nВот улучшенная версия кода:\n\n```python\n#!/usr/bin/env python3\n\"\"\"Fix CSV file by removing invalid header rows\"\"\"\n\nimport csv\nimport sys\n\ninput_file = \"training-data/medical_training_data.csv\"\noutput_file = \"training-data/cleaned_medical_training_data.csv\"\n\n# Read the CSV file and filter out invalid lines\nwith open(input_file, \"r\", encoding=\"utf-8\") as f:\n    reader = csv.reader(f)\n    valid_lines = [row for i, row in enumerate(reader) if i == 0 or ',' in row]\n\n# Write back the cleaned CSV\nwith open(output_file, \"w\", encoding=\"utf-8\") as f:\n    writer = csv.writer(f)\n    writer.writerows(valid_lines)\n\nprint(\n    f\"\\nDone! Kept {len(valid_lines)} valid lines, removed {len(lines) - len(valid_lines)} invalid lines\"\n)\n```\n\nПожалуйста, обратите внимание, что в этом коде мы предполагаем, что некорректные строки не содержат запятых. Если это не так, вам потребуется более сложная логика для определения валидности строки.",
    "lines_of_code": 29
  }
]