[
  {
    "file": "train.py",
    "timestamp": "2025-11-11T03:44:01.259454",
    "metrics": {
      "complexity": "train.py\n    F 77:0 train_model - A (4)\n    F 47:0 prepare_data - A (3)\n    C 22:0 MedicalDataset - A (2)\n    M 23:4 MedicalDataset.__init__ - A (1)\n    M 28:4 MedicalDataset.__len__ - A (1)\n    M 31:4 MedicalDataset.__getitem__ - A (1)\n",
      "maintainability": "train.py - A (69.54)\n"
    },
    "ai_recommendations": "Ваш код в целом хорошо структурирован и читаем. Однако есть несколько областей, которые можно улучшить:\n\n1. **Обработка ошибок и валидация входных данных**: Ваш код должен обрабатывать исключения и ошибки, которые могут возникнуть при чтении CSV-файла. Например, если файл не существует или содержит некорректные данные. Также стоит добавить проверку на пустые строки в столбце 'text'.\n\n2. **Константы и глобальные переменные**: Вместо использования глобальных переменных, таких как MODEL_NAME и DEVICE, рассмотрите возможность передачи их в качестве аргументов функции. Это улучшит модульность и повторное использование кода.\n\n3. **Очистка данных**: Ваш код очищает данные, удаляя пробелы в начале и конце каждого текста. Возможно, стоит добавить больше этапов предобработки, таких как преобразование всех символов в нижний регистр, удаление знаков препинания и т.д.\n\n4. **Оптимизация использования памяти**: Ваш код загружает все данные в память сразу. Если у вас большой набор данных, это может привести к проблемам с памятью. Рассмотрите возможность использования генераторов Python для загрузки и обработки данных по частям.\n\n5. **Логирование**: Ваш код использует логирование для отслеживания прогресса обучения модели. Возможно, стоит добавить больше информации в логи, таких как текущая эпоха, общее количество эпох, потери на каждой эпохе и т.д.\n\n6. **Сохранение и загрузка модели**: Ваш код сохраняет модель после обучения, но не предоставляет функциональности для загрузки обученной модели. Это может быть полезно, если вы хотите продолжить обучение модели с того места, где остановились, или использовать обученную модель для предсказаний.\n\n7. **Сохранение промежуточных результатов**: Ваш код сохраняет обучающие и тестовые данные в CSV-файлы, но не сохраняет промежуточные результаты обучения, такие как потери на каждой эпохе. Это может быть полезно для отслеживания прогресса обучения и отладки.\n\n8. **Оптимизация производительности**: Ваш код использует AdamW в качестве оптимизатора. Возможно, стоит рассмотреть другие оптимизаторы или настройки оптимизатора для улучшения производительности обучения.",
    "lines_of_code": 124
  },
  {
    "file": "main.py",
    "timestamp": "2025-11-11T03:44:22.445275",
    "metrics": {
      "complexity": "main.py\n    F 32:0 train_model - A (4)\n    F 72:0 predict - A (2)\n    C 14:0 MedicalNet - A (2)\n    F 92:0 main - A (1)\n    M 15:4 MedicalNet.__init__ - A (1)\n    M 22:4 MedicalNet.forward - A (1)\n",
      "maintainability": "main.py - A (74.92)\n"
    },
    "ai_recommendations": "В целом, код хорошо структурирован и легко читаем. Однако, есть несколько моментов, которые можно улучшить:\n\n1. **Импорты**: Импорт модуля `os` не используется в коде, его можно удалить.\n\n2. **Документация**: В коде отсутствуют комментарии и docstrings, которые бы объясняли, что делает каждая функция и класс. Это делает код менее понятным для других разработчиков.\n\n3. **Обработка ошибок**: В коде нет обработки исключений, что может привести к непредсказуемым ошибкам. Например, при загрузке модели из файла, если файл не найден, будет сгенерировано исключение.\n\n4. **Жесткое кодирование**: В коде присутствуют \"магические числа\", такие как размеры входного и скрытого слоя, количество эпох, размер батча и т.д. Лучше вынести эти значения в конфигурационные переменные или аргументы функций.\n\n5. **Производительность**: Вместо использования `torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")` в каждой функции, можно определить устройство один раз в начале и использовать его во всем коде.\n\n6. **Модульность**: Функции `train_model` и `predict` выполняют слишком много задач. Лучше разделить их на более мелкие функции, каждая из которых выполняет одну задачу.\n\n7. **Сохранение и загрузка модели**: Вместо сохранения только параметров модели, можно сохранить всю модель, включая ее структуру. Это позволит загрузить модель без необходимости заново определять ее структуру.\n\n8. **Вывод информации во время обучения**: Вместо вывода потерь после каждой эпохи, можно использовать библиотеку, такую как `tqdm`, для отображения прогресса обучения.\n\n9. **Обучение модели**: В коде отсутствует валидационный этап, который позволил бы проверить качество модели на данных, которые она не видела во время обучения.\n\n10. **Best practices**: Вместо использования `torch.tensor(data, dtype=torch.float32)` лучше использовать `data = data.astype(np.float32)` перед преобразованием в тензор, чтобы избежать неявного преобразования типов данных.",
    "lines_of_code": 111
  },
  {
    "file": "infer.py",
    "timestamp": "2025-11-11T03:44:45.805311",
    "metrics": {
      "complexity": "infer.py\n    F 10:0 infer_model - A (2)\n",
      "maintainability": "infer.py - A (74.30)\n"
    },
    "ai_recommendations": "В целом, код хорошо структурирован и читаем. Однако, есть несколько мест, которые можно улучшить:\n\n1. **Производительность**: Загрузка модели и токенизатора из директории происходит при каждом вызове функции `infer_model()`. Это может быть неэффективно, если функция вызывается многократно. Лучше загрузить модель и токенизатор один раз и затем использовать их для всех последующих вызовов функции. \n\n2. **Читаемость**: Хотя код вполне читаем, можно добавить комментарии к функции `infer_model()` для объяснения того, что она делает, и к каждому шагу внутри функции. Это поможет другим разработчикам быстрее понять, что делает ваш код.\n\n3. **Best Practices**: Вместо прямого использования `print` для вывода результатов, рассмотрите возможность использования стандартного модуля `logging` Python. Это позволит вам более гибко управлять уровнем детализации сообщений, а также перенаправлять их в файлы журнала при необходимости.\n\n4. **Безопасность**: В этом коде нет явных проблем с безопасностью. Однако, следует убедиться, что используемые модели и токенизаторы загружаются из надежных источников.\n\nИтак, улучшенный код может выглядеть следующим образом:\n\n```python\nimport argparse\nimport torch\nfrom transformers import AutoModelForSequenceClassification, AutoTokenizer\nimport logging\n\n# Настройка устройства\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n# Настройка логирования\nlogging.basicConfig(level=logging.INFO)\n\n# Загрузка модели и токенизатора один раз\nMODEL_DIR = \"path_to_your_model\"\nTOKENIZER = AutoTokenizer.from_pretrained(MODEL_DIR)\nMODEL = AutoModelForSequenceClassification.from_pretrained(MODEL_DIR)\nMODEL.to(DEVICE)\n\ndef infer_model(text):\n    \"\"\"\n    Функция для инференса модели.\n    Вход: текст для анализа\n    Выход: вероятности классов\n    \"\"\"\n    tokens = TOKENIZER(\n        text, return_tensors=\"pt\", truncation=True, padding=True, max_length=128\n    )\n    tokens = {k: v.to(DEVICE) for k, v in tokens.items()}\n\n    MODEL.eval()\n    with torch.no_grad():\n        outputs = MODEL(**tokens)\n        probabilities = torch.softmax(outputs.logits, dim=-1)\n\n    return probabilities.tolist()\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser(description=\"Инференс с медицинской нейросетью\")\n    parser.add_argument(\"--text\", required=True, help=\"Текст для анализа\")\n    args = parser.parse_args()\n\n    result = infer_model(args.text)\n    logging.info(f\"Результаты предсказания: {result}\")\n```\n\nПожалуйста, обратите внимание, что в этом коде `MODEL_DIR` захардкожен. В реальном приложении вы, вероятно, захотите сделать его конфигурируемым.",
    "lines_of_code": 35
  },
  {
    "file": "prepare_data.py",
    "timestamp": "2025-11-11T03:45:04.788477",
    "metrics": {
      "complexity": "prepare_data.py\n    F 13:0 prepare_data - A (3)\n",
      "maintainability": "prepare_data.py - A (84.99)\n"
    },
    "ai_recommendations": "В целом, код хорошо структурирован, читаем и следует большинству best practices. Однако, есть несколько предложений по улучшению:\n\n1. **Обработка исключений:** Ваш код может вызвать исключение, если файл CSV не найден или не может быть прочитан. Рекомендуется добавить обработку исключений для этих сценариев.\n\n2. **Проверка входных данных:** Ваш код предполагает, что столбцы 'text' и 'label' присутствуют в данных. Если это не так, код вызовет исключение. Хотя вы и проверяете наличие этих столбцов, было бы полезно добавить более ясное сообщение об ошибке, чтобы пользователь понимал, что не так с его данными.\n\n3. **Оптимизация использования памяти:** Ваш код загружает весь CSV-файл в память с помощью `pd.read_csv()`. Если файл очень большой, это может привести к проблемам с памятью. Рассмотрите возможность использования параметра `chunksize` в `pd.read_csv()` для чтения файла по частям.\n\n4. **Добавление аргумента для установки размера тестовой выборки:** В настоящее время размер тестовой выборки зафиксирован на уровне 20%. Было бы полезно добавить аргумент командной строки, который позволил бы пользователю устанавливать этот размер самостоятельно.\n\n5. **Добавление документации:** Хотя функция `prepare_data` имеет строку документации, было бы полезно добавить комментарии к остальной части кода, особенно к блоку `if __name__ == \"__main__\":`, чтобы помочь другим разработчикам понять, что делает ваш код.\n\n6. **Использование f-строк:** Вы уже используете f-строки для форматирования строк, что является хорошей практикой для улучшения читаемости кода. Продолжайте в том же духе!\n\n7. **Безопасность:** Ваш код не содержит явных угроз безопасности, так как он не обрабатывает конфиденциальные данные и не взаимодействует с внешними системами. Однако всегда стоит быть внимательным и следить за обновлениями библиотек, которые вы используете, чтобы избежать возможных уязвимостей.",
    "lines_of_code": 53
  },
  {
    "file": "scripts/fix_csv_headers.py",
    "timestamp": "2025-11-11T03:45:24.403821",
    "metrics": {
      "complexity": "",
      "maintainability": "scripts/fix_csv_headers.py - A (90.78)\n"
    },
    "ai_recommendations": "В целом, код выглядит хорошо, но есть несколько мест, которые можно улучшить:\n\n1. **Производительность**: Вместо того, чтобы сначала считывать все строки в список, а затем фильтровать их, можно сразу же фильтровать строки при чтении. Это позволит уменьшить использование памяти и увеличить скорость обработки для больших файлов.\n\n2. **Читаемость**: Вместо использования индекса `i` для проверки первой строки, можно использовать флаг, который будет более понятным.\n\n3. **Best practices**: Лучше избегать использования прямого пути к файлу в коде. Вместо этого можно передавать путь к файлу как аргумент командной строки.\n\n4. **Безопасность**: При записи в тот же файл, что и исходный, есть риск потери данных в случае ошибки. Лучше записывать в новый файл, а затем переименовывать его.\n\nВот улучшенная версия кода:\n\n```python\n#!/usr/bin/env python3\n\"\"\"Fix CSV file by removing invalid header rows\"\"\"\n\nimport csv\nimport sys\nimport os\n\ndef fix_csv_headers(file_path):\n    # Temporary file to store valid lines\n    temp_file_path = file_path + '.tmp'\n\n    with open(file_path, \"r\", encoding=\"utf-8\") as f, open(temp_file_path, \"w\", encoding=\"utf-8\") as temp_f:\n        is_header = True\n        valid_lines = 0\n        total_lines = 0\n\n        for line in f:\n            total_lines += 1\n            if is_header or \",\" in line:  # Keep the header row and lines with CSV data\n                temp_f.write(line)\n                valid_lines += 1\n                is_header = False\n            else:\n                print(f\"Removing invalid line {total_lines}: {line.strip()}\")\n\n    # Rename the temp file\n    os.rename(temp_file_path, file_path)\n\n    print(\n        f\"\\nDone! Kept {valid_lines} valid lines, removed {total_lines - valid_lines} invalid lines\"\n    )\n\nif __name__ == \"__main__\":\n    if len(sys.argv) != 2:\n        print(\"Usage: python fix_csv_headers.py <file_path>\")\n        sys.exit(1)\n\n    fix_csv_headers(sys.argv[1])\n```\n\nТеперь этот скрипт можно запускать из командной строки с путем к файлу в качестве аргумента, например: `python fix_csv_headers.py training-data/medical_training_data.csv`.",
    "lines_of_code": 29
  }
]