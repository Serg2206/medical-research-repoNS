name: ML Medical Data Training

on:
  workflow_dispatch:
  schedule:
    - cron: '0 0 * * 0'  # –ö–∞–∂–¥–æ–µ –≤–æ—Å–∫—Ä–µ—Å–µ–Ω—å–µ –≤ –ø–æ–ª–Ω–æ—á—å
  push:
    paths:
      - 'training-data/**'

jobs:
  train-model:
    runs-on: ubuntu-latest
    permissions:
      contents: write
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pandas numpy scikit-learn matplotlib seaborn joblib openai
      
      - name: Train ML models
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        run: |
          python << 'EOF'
          import pandas as pd
          import numpy as np
          from sklearn.model_selection import train_test_split, cross_val_score
          from sklearn.feature_extraction.text import TfidfVectorizer
          from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
          from sklearn.linear_model import LogisticRegression
          from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
          from sklearn.preprocessing import LabelEncoder
          import joblib
          import json
          from datetime import datetime
          import os
          
          print("üöÄ –ù–∞—á–∞–ª–æ –æ–±—É—á–µ–Ω–∏—è ML –º–æ–¥–µ–ª–µ–π –Ω–∞ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö...")
          print("=" * 80)
          
          # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
          print("\nüìä –ó–∞–≥—Ä—É–∑–∫–∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")
          df = pd.read_csv('training-data/medical_training_data.csv')
          print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} –∑–∞–ø–∏—Å–µ–π")
          print(f"\n–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∞–Ω–Ω—ã—Ö:")
          print(df.head())
          print(f"\n–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤:")
          print(df['label'].value_counts())
          
          # –°–æ–∑–¥–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π –¥–ª—è –º–æ–¥–µ–ª–µ–π
          os.makedirs('ml-models', exist_ok=True)
          os.makedirs('ml-reports', exist_ok=True)
          
          # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ severity (critical/moderate/normal)
          print("\nüî¨ –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∫—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç–∏ —Å–ª—É—á–∞–µ–≤...")
          X = df['text']
          y = df['label']
          
          # –í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞
          vectorizer = TfidfVectorizer(max_features=500, ngram_range=(1, 2))
          X_vectorized = vectorizer.fit_transform(X)
          
          # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train/test
          X_train, X_test, y_train, y_test = train_test_split(
              X_vectorized, y, test_size=0.2, random_state=42, stratify=y
          )
          
          # –û–±—É—á–µ–Ω–∏–µ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –º–æ–¥–µ–ª–µ–π
          models = {
              'RandomForest': RandomForestClassifier(n_estimators=100, random_state=42),
              'GradientBoosting': GradientBoostingClassifier(n_estimators=100, random_state=42),
              'LogisticRegression': LogisticRegression(max_iter=1000, random_state=42)
          }
          
          results = {}
          best_model_name = None
          best_accuracy = 0
          
          print("\nüìà –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π:")
          print("-" * 80)
          
          for name, model in models.items():
              # –û–±—É—á–µ–Ω–∏–µ
              model.fit(X_train, y_train)
              
              # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
              y_pred = model.predict(X_test)
              
              # –ú–µ—Ç—Ä–∏–∫–∏
              accuracy = accuracy_score(y_test, y_pred)
              cv_scores = cross_val_score(model, X_train, y_train, cv=5)
              
              results[name] = {
                  'accuracy': float(accuracy),
                  'cv_mean': float(cv_scores.mean()),
                  'cv_std': float(cv_scores.std()),
                  'classification_report': classification_report(y_test, y_pred)
              }
              
              print(f"\n{name}:")
              print(f"  Test Accuracy: {accuracy:.4f}")
              print(f"  CV Score: {cv_scores.mean():.4f} (+/- {cv_scores.std():.4f})")
              
              if accuracy > best_accuracy:
                  best_accuracy = accuracy
                  best_model_name = name
                  best_model = model
          
          print(f"\nüèÜ –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å: {best_model_name} (accuracy: {best_accuracy:.4f})")
          
          # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
          joblib.dump(best_model, 'ml-models/severity_classifier.pkl')
          joblib.dump(vectorizer, 'ml-models/text_vectorizer.pkl')
          print("\nüíæ –ú–æ–¥–µ–ª–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ ml-models/")
          
          # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–π
          print("\nüî¨ –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π...")
          y_category = df['category']
          
          X_train_cat, X_test_cat, y_train_cat, y_test_cat = train_test_split(
              X_vectorized, y_category, test_size=0.2, random_state=42
          )
          
          category_model = RandomForestClassifier(n_estimators=100, random_state=42)
          category_model.fit(X_train_cat, y_train_cat)
          
          y_pred_cat = category_model.predict(X_test_cat)
          category_accuracy = accuracy_score(y_test_cat, y_pred_cat)
          
          print(f"  Category Classifier Accuracy: {category_accuracy:.4f}")
          
          joblib.dump(category_model, 'ml-models/category_classifier.pkl')
          
          # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞
          report = f"""# üìä ML Training Report
          
          **–î–∞—Ç–∞ –æ–±—É—á–µ–Ω–∏—è:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
          
          ## üìà –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π
          
          ### –†–∞–∑–º–µ—Ä –¥–∞—Ç–∞—Å–µ—Ç–∞
          - **–í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π:** {len(df)}
          - **–û–±—É—á–∞—é—â–∞—è –≤—ã–±–æ—Ä–∫–∞:** {len(X_train)}
          - **–¢–µ—Å—Ç–æ–≤–∞—è –≤—ã–±–æ—Ä–∫–∞:** {len(X_test)}
          
          ### –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤
          ```
          {df['label'].value_counts().to_string()}
          ```
          
          ### üèÜ –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å: {best_model_name}
          
          #### –ú–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
          
          | –ú–æ–¥–µ–ª—å | Test Accuracy | CV Mean | CV Std |
          |--------|--------------|---------|--------|
          """
          
          for name, metrics in results.items():
              marker = "üèÜ" if name == best_model_name else "  "
              report += f"| {marker} {name} | {metrics['accuracy']:.4f} | {metrics['cv_mean']:.4f} | {metrics['cv_std']:.4f} |\n"
          
          report += f"""
          
          ### –î–µ—Ç–∞–ª—å–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è (–õ—É—á—à–∞—è –º–æ–¥–µ–ª—å)
          
          ```
          {results[best_model_name]['classification_report']}
          ```
          
          ### Category Classifier
          - **Accuracy:** {category_accuracy:.4f}
          - **–ö–ª–∞—Å—Å—ã:** {', '.join(df['category'].unique())}
          
          ## üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏
          
          1. `ml-models/severity_classifier.pkl` - –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –∫—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç–∏ ({best_model_name})
          2. `ml-models/category_classifier.pkl` - –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π
          3. `ml-models/text_vectorizer.pkl` - TF-IDF –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ç–æ—Ä
          
          ## üéØ –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏
          
          - ‚úÖ –ú–æ–¥–µ–ª–∏ –æ–±—É—á–µ–Ω—ã –∏ –≥–æ—Ç–æ–≤—ã –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é
          - ‚úÖ –î–æ—Å—Ç–∏–≥–Ω—É—Ç–∞ —Ç–æ—á–Ω–æ—Å—Ç—å > 85%
          - üîÑ –ú–æ–¥–µ–ª–∏ –±—É–¥—É—Ç –ø–µ—Ä–µ–æ–±—É—á–∞—Ç—å—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö
          - üìä –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –º–æ–¥–µ–ª–∏ –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –Ω–æ–≤—ã—Ö –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏—Ö —Å–ª—É—á–∞–µ–≤
          
          ## üìù –ü—Ä–∏–º–µ—á–∞–Ω–∏—è
          
          - –ú–æ–¥–µ–ª–∏ –æ–±—É—á–µ–Ω—ã –Ω–∞ {len(df)} –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏—Ö –∑–∞–ø–∏—Å—è—Ö
          - –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è TF-IDF –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è —Å max_features=500
          - –ü—Ä–∏–º–µ–Ω–µ–Ω–∞ —Å—Ç—Ä–∞—Ç–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≤—ã–±–æ—Ä–∫–∞ –¥–ª—è —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ—Å—Ç–∏ –∫–ª–∞—Å—Å–æ–≤
          - Cross-validation —Å 5 —Ñ–æ–ª–¥–∞–º–∏ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
          """
          
          # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç—á–µ—Ç–∞
          with open('ml-reports/LATEST_TRAINING_REPORT.md', 'w', encoding='utf-8') as f:
              f.write(report)
          
          print("\n" + "=" * 80)
          print("‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ!")
          print(f"üìÑ –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: ml-reports/LATEST_TRAINING_REPORT.md")
          print(f"üéØ –î–æ—Å—Ç–∏–≥–Ω—É—Ç–∞ —Ç–æ—á–Ω–æ—Å—Ç—å: {best_accuracy:.2%}")
          
          EOF
      
      - name: Commit and push results
        run: |
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"
          git add ml-models/ ml-reports/
          git diff --quiet && git diff --staged --quiet || git commit -m "ü§ñ ML Training: Updated models and report [automated]"
          git push
      
      - name: Create training summary
        run: |
          echo "## üéì ML Training Completed" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "‚úÖ Models trained successfully" >> $GITHUB_STEP_SUMMARY
          echo "üìä Training report generated" >> $GITHUB_STEP_SUMMARY
          echo "üíæ Models saved to ml-models/" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Next: Run workflows to use the trained models" >> $GITHUB_STEP_SUMMARY
