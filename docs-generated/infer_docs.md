# Documentation: infer.py

**Файл:** `infer.py`

**Дата:** 2025-11-19

---

# Документация

## Описание функционала

Этот скрипт Python использует предварительно обученную модель для классификации текста. Он использует библиотеку transformers от Hugging Face для загрузки модели и токенизации входного текста. Затем он выполняет инференс модели на входном тексте и возвращает вероятности для каждого класса.

## Функции

### infer_model(model_dir: str, text: str) -> List[float]

#### Описание

Функция выполняет инференс модели на входном тексте и возвращает вероятности для каждого класса.

#### Параметры

- `model_dir` (str): Путь к директории с сохраненной моделью. Модель должна быть совместима с библиотекой transformers.
- `text` (str): Входной текст для инференса модели.

#### Возвращаемое значение

- `List[float]`: Список вероятностей для каждого класса.

## Примеры использования

### Использование из командной строки

```bash
python script.py --model /path/to/model --text "Ваш текст для анализа"
```

### Использование в коде Python

```python
result = infer_model("/path/to/model", "Ваш текст для анализа")
print(f"Результаты предсказания: {result}")
```

## Примечания

- Убедитесь, что у вас установлены все необходимые зависимости, включая torch и transformers.
- Если у вас есть GPU, этот скрипт автоматически будет использовать его для ускорения инференса.
- Максимальная длина входного текста ограничена 128 токенами. Если входной текст длиннее, он будет обрезан.