# Documentation: train.py

**Файл:** `train.py`

**Дата:** 2025-11-10

---

# Документация

## Описание функционала

Этот код представляет собой скрипт на Python для обучения модели классификации последовательности с использованием предварительно обученной модели BERT. Он включает в себя функцию для подготовки данных и класс для создания набора данных, который может быть использован для обучения и тестирования модели.

## Параметры и возвращаемые значения

### Класс `MedicalDataset`

- `__init__(self, data, tokenizer, max_length=128)`: Инициализирует объект `MedicalDataset`. Принимает в качестве аргументов данные, токенизатор и максимальную длину последовательности. Не возвращает значение.

- `__len__(self)`: Возвращает длину данных. Не принимает аргументов.

- `__getitem__(self, idx)`: Возвращает токенизированный элемент данных по индексу. Принимает в качестве аргумента индекс. Возвращает кортеж, содержащий токенизированные входные данные, маску внимания и метку.

### Функция `prepare_data`

- `prepare_data(input_csv, output_dir, test_size=0.2)`: Подготавливает данные, разделяя их на обучающую и тестовую выборки. Принимает в качестве аргументов путь к входному CSV-файлу, директорию для сохранения обработанных данных и размер тестовой выборки. Не возвращает значение.

## Примеры использования

```python
# Инициализация токенизатора
tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)

# Подготовка данных
prepare_data("input.csv", "output/", test_size=0.2)

# Загрузка данных
data = pd.read_csv("output/train.csv")

# Создание набора данных
dataset = MedicalDataset(data, tokenizer, max_length=128)

# Получение элемента данных
item = dataset[0]
```

Обратите внимание, что в этом примере используется предварительно обученная модель BERT, и вам необходимо установить соответствующий токенизатор. Входные данные должны быть в формате CSV и содержать столбцы "text" и "label".